---
title: 'Assessing the agreement between two quantitative methods of measurements :
  understanding the Bland Altman analysis'
author: Thomas Goossens
date: '2018-02-28'
categories:
  - R
  - how-to
tags:
  - statistics
---



<p>Attempting to statistically assess the agreement between two quantitative methods of measurements requires a validation tool.</p>
<p>A widely adopted tool is the correlation study computed with one method as predictor and the other as response variable (e.g. see <a href="http://onlinelibrary.wiley.com/doi/10.1002/wea.2158/pdf">this</a> publication that compares temperature measurements obtained by two different kind of weather stations at the exact same location).</p>
<p>However, as described by <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4470095/">Giavarina (2015)</a>, correlation study should not be used to asses the comparatibility or agreement between two instruments (because it studies the relation between one variable and the other and not the <strong>differences</strong>).</p>
<p>In 1986, <a href="https://www-users.york.ac.uk/~mb55/meas/ba.pdf">Bland and Altman</a> have proposed an analysis that quantifies the agreement between two quantitative sets of measurements of the same parameter by statistically studying the behaviors of the differences between paired measurements. This analysis is useful to determine if a method can be used interoperably with another without the need of a correction model</p>
<div id="some-words-about-measurements-difference" class="section level2">
<h2>Some words about measurements difference</h2>
<p>From <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4470095/">Giavarina (2015)</a> :</p>
<blockquote>
<p>An ideal model would claim that the measurements obtained by one method or another gave exactly the same results. So, all the differences would be equal to zero. But any measurement of variables always implies some degree of error. Even the mere analytical imprecision for method A and method B generates a variability of the differences. However, if the variability of the differences were only linked to analytical imprecision of each of the two methods, the average of these differences should be zero. This is the first point required to evaluate the agreement between the two methods: look at the average of the differences between the paired data.</p>
</blockquote>
</div>
<div id="quick-presentation-of-the-bland-altman-analysis" class="section level2">
<h2>Quick presentation of the Bland Altman analysis</h2>
<p>Their graphical method plots the <strong>differences between the two paired measurements</strong> against <strong>the averages of these measurements</strong>.</p>
<p>Here is an examplative Bland-Altman plot : [blandAltman plot example]({{ “/assets/images/blandAltman.png” | absolute_url }})</p>
<p><em><a href="https://cran.r-project.org/web/packages/BlandAltmanLeh/vignettes/Intro.html">Source</a></em></p>
<p>Horizontal lines are drawn at the <strong>mean difference</strong> (thick red line), and at the upper and lower <strong>limits of agreement</strong> (thick blue lines) together with their 0.95 <a href="https://www.mathsisfun.com/data/confidence-interval.html">confidence interval - CI</a> (thin lines).</p>
<ul>
<li><p>The <strong>mean difference</strong> is the estimated <strong>bias</strong>. Its 0.95 CI illustrates the magnitude of the systematic difference.</p></li>
<li><p>The <strong>limits of agreement</strong> measure the <strong>random fluctuations around the mean difference</strong>. These correspond to the mean difference plus and minus 1.96 times the standard deviation of the differences. These lines tell us how far apart measurements by 2 methods were more likely to be for most individuals.</p></li>
<li><p><strong>The Maximum allowed difference between methods (D)</strong> is an arbitrary treshold which value must be chosen so that differences in the range −D to D are considered irrelevant or neglectable in the context of your study.</p></li>
</ul>
</div>
<div id="interpretation-guidelines" class="section level2">
<h2>Interpretation guidelines</h2>
<p>The plot allows to infer some information about the agreement of two methods :</p>
<ul>
<li><p>If the line of equality (horizontal line at 0) is not in the mean difference 0.95 CI, there is a <strong>significant systematic difference</strong>.</p></li>
<li><p>If the mean value of the difference differs significantly from 0, this indicates the presence of a <strong>fixed bias</strong>. This bias can be adjusted for by subtracting the mean difference from the the measurements of the method we want to determine if it can substituate the other.</p></li>
<li><p>If the limits of agreement do not exceed the maximum allowed difference, the two methods are considered to be <strong>in agreement</strong>. They are therefore considered as interchangeable. This interpretation does not however takes CI into accounts (see next point).</p></li>
<li><p>If the maximum allowed difference is higher than the 0.95 upper limit of the higher limit of agreement and if the maximum allowed difference is lower than the 0.95 lower limit of the lower limit, we are <strong>95% certain that the methods do not disagree</strong> (if the differences are <a href="https://rexplorations.wordpress.com/2015/08/11/normality-tests-in-r/">normally distributed</a>).</p></li>
<li><p>If the scatter presents a trend, there is a relationship between the differences and the magnitude of measurements (<strong>proportional error/bias</strong>). The existence of such a proportional bias indicates that the methods do not agree equally through the range of measurements. To formally evaluate this relationship, one could compute a regression model between the difference and the average of the 2 methods.</p></li>
</ul>
</div>
<div id="some-usage-precautions" class="section level2">
<h2>Some usage precautions</h2>
<p>The Bland and Altman analysis allows to determine if the bias is significant (e.i. the line of equality is not within the confidence interval of the mean difference) <strong>but</strong> it does not allow to say if the agreement is sufficient or suitable for your instruments interoperability.</p>
<p>This analysis modestly quantifies the bias and a range of agreement within which 95% of the differences between one measurement and the other are included.</p>
<p>Only the <strong>context of your analysis</strong> could define whether the agreement interval is too wide or sufficiently narrow for your purpose. This is why you should arbitrary set the limits of maximum acceptable differences (limits of agreement expected) based on relevant criteria defined in the context of your analysis.</p>
</div>
<div id="software-implementation" class="section level2">
<h2>Software implementation</h2>
<p>I mainly work in R (<a href="https://www.r-bloggers.com/why-use-r-five-reasons/">and you should too</a>). If you already do so, I would recommand you the excellent <a href="https://cran.r-project.org/web/packages/BlandAltmanLeh/vignettes/Intro.html">BlandAltmanLeh</a> package that is sufficiently well document in order to perform your own Bland Altman analysis.</p>
</div>
<div id="see-also" class="section level2">
<h2>See also</h2>
<ul>
<li><a href="https://www.medcalc.org/manual/blandaltman.php">medcalc.org Bland Altman explanation page</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bland%E2%80%93Altman_plot#/media/File:Bland-Alman_Plot_with_CI%27s_on_LOA.png">Bland Altman Wikipedia page</a></li>
<li><a href="https://repository.uwl.ac.uk/id/eprint/2044/1/Amoako-Attah-Jahromi-2015-Method-comparison-analysis-of-dwellings-temperatures-in-the-UK.pdf">a scientific paper that presents a use case of Bland Altman study in the context of temperature measurement</a></li>
</ul>
</div>
