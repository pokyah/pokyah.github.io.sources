<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pokyah - opensource science, GIS and data-analysis</title>
    <link>/</link>
    <description>Recent content on pokyah - opensource science, GIS and data-analysis</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Thu, 23 Aug 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Building a dockerized shiny server with packaged shiny apps and deploy it publicly in 2 minutes</title>
      <link>/post/2018-08-01-building-a-dockerized-shiny-server-with-packaged-shiny-apps/</link>
      <pubDate>Thu, 23 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-08-01-building-a-dockerized-shiny-server-with-packaged-shiny-apps/</guid>
      <description>&lt;p&gt;Let‚Äôs imagine you want to build an interactive data vizualization app that could be accessible from the internet. As an R expert, one of your best bet could be to use the power of shiny apps. You probably wonder what could be one of the most efficient way to easily and quickly deploy it ? Let‚Äôs find out how the magic of docker and R packages will help you achieve this !&lt;/p&gt;
&lt;div id=&#34;write-your-shiny-app-as-a-package&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Write your shiny App as a package&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wlandau.github.io/2016/11/01/appPackage/&#34;&gt;Building shiny apps as package&lt;/a&gt; will help you to produce a cleaner and easier to maintain code thanks to devtools and testthat. I heavily recommand you to code your app this way. Doing so will also allow you to use &lt;code&gt;devtools::install_github()&lt;/code&gt; to quickly install your app on any computer, server and Docker container.&lt;/p&gt;
&lt;p&gt;Moreover R packages are &lt;a href=&#34;https://kbroman.org/pkg_primer/pages/why.html&#34;&gt;the most efficient way to make reproductible science&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To understand how to code your shiny app as a package, Dean Attali‚Äôs answers in &lt;a href=&#34;https://stackoverflow.com/questions/37830819/developing-shiny-app-as-a-package-and-deploying-it-to-shiny-server&#34;&gt;this&lt;/a&gt; stackoveflow thread, and his blog post &lt;a href=&#34;https://deanattali.com/2015/04/21/r-package-shiny-app/&#34;&gt;‚ÄúSupplementing your R package with a Shiny app‚Äù&lt;/a&gt; are excellent starting points.&lt;/p&gt;
&lt;p&gt;Follow the instructions and make sure that your shiny app code is placed into the &lt;code&gt;inst&lt;/code&gt; folder of your package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-shiny-server-docker-image-which-contains-the-packaged-shiny-apps&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Create a shiny server docker image which contains the packaged shiny app(s)&lt;/h1&gt;
&lt;p&gt;A &lt;a href=&#34;https://shiny.rstudio.com/articles/shiny-server.html&#34;&gt;shiny server&lt;/a&gt; allows you to distribute multiple shiny apps over the internet at their own URL in an easy and efficient way. Setting up a shiny server may be time consuming but thanks to Docker and the &lt;a href=&#34;https://www.rocker-project.org/&#34;&gt;rocker-org community&lt;/a&gt;, you can now quickly set up your own shiny server ! To do so, simply clone the rocker-org shiny server &lt;a href=&#34;https://github.com/tocker-org/shiny-1&#34;&gt;repo&lt;/a&gt; :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ git clone git@github.com:rocker-org/shiny.git&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Open the Dockerfile (which is the recipe to create the Docker image that will be used to instantiate the shiny server) and add the instruction line to add your packaged shinyApp to your Docker image. If your packaged app is pushed to a github repository, paste this line in the Dockerfile and adapt the &amp;lt;PLACEHOLDERS&amp;gt; :&lt;/p&gt;
&lt;p&gt;&lt;code&gt;RUN R -e &amp;quot;devtools::install_github(&#39;&amp;lt;GITHUB_USERNAME&amp;gt;/&amp;lt;PACKAGE_REPO_NAME&amp;gt;&#39;, ref=&#39;&amp;lt;BRANCHNAME&amp;gt;&#39;, force=TRUE)&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Repeat this step for every packaged shiny app you want to be accessible through your dockerized shiny server. Save your work and push it to github.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;make-your-docker-shiny-server-image-accessible-through-docker-hub&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Make your docker shiny server image accessible through docker hub&lt;/h1&gt;
&lt;p&gt;This step will later allows you to quickly install and instantiate the shiny server docker container. To do so, simply link your github and dockerhub accounts by following the instructions provided in &lt;a href=&#34;https://felixcentmerino.wordpress.com/containers/sync-up-docker-hub-and-github-to-build-images-automatically/&#34;&gt;this post&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;install-the-docker-shiny-server-image-on-your-server&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Install the docker shiny server image on your server&lt;/h1&gt;
&lt;p&gt;Once docker hub shows that the image build is ready with no errors, download the image on your host server by adapting this command :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ sudo docker pull &amp;lt;DOCKERHUB_USERNAME/IMAGENAME&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point, you only need some extra lines of R code to actually deploy your packaged shiny apps ! As your shiny apps source files are located into the &lt;a href=&#34;http://r-pkgs.had.co.nz/inst.html&#34;&gt;&lt;code&gt;inst&lt;/code&gt; folder&lt;/a&gt; of your packages, you will use the &lt;code&gt;sytem.file&lt;/code&gt; function to actually call and initiate these. On your host server, create a folder and name it for example &lt;code&gt;shiny_launchers_mountpoint&lt;/code&gt;. Inside this folder, create a folder for each of the shiny apps you have add to your Docker image, and give these folders the same name as your packaged shiny apps. Finally, inside each of this folder create and &lt;code&gt;app.R&lt;/code&gt; file that contains the following lines (of course, don‚Äôt forget to adapt the &amp;lt;PLACEHOLDERS&amp;gt;) :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dir &amp;lt;- system.file(&amp;quot;&amp;lt;SHINY_APP_CODE_LOCATION_INSIDE_INST_FOLDER&amp;gt;&amp;quot;, package = &amp;quot;&amp;lt;PACKAGE_REPO_NAME&amp;gt;&amp;quot;)
setwd(dir)
shiny::shinyAppDir(&amp;quot;.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At the root of the &lt;code&gt;shiny_launchers_mountpoint&lt;/code&gt; create an index.html file that will act as the homepage of your shiny server. You can put whatver you want into it. A good idea is to create a link for each of your shiny apps.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;instantiate-your-docker-container&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Instantiate your docker container&lt;/h1&gt;
&lt;p&gt;Now that all of your infrastructure is ready, the last step is to run your shiny server. In your host server terminal, run this command to instantiate your shiny apps server container in detached mode :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;sudo docker run -d --rm -p 3838:3838 -v &amp;lt;FULL_PATH_OF_YOUR_FOLDER_CONTAINING_THE_R_SCRIPT&amp;gt;:/srv/shiny-server/     -v /srv/shinylog/:/var/log/shiny-server/     &amp;lt;DOCKERHUB_USERNAME&amp;gt;/&amp;lt;REPONAME&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now head at &lt;code&gt;localhost:3838/apps&lt;/code&gt; into your browser and your index.html file will be served. Click on the link of the shiny app you want to consult and you are done !&lt;/p&gt;
&lt;p&gt;If you want to consult it from another computer, replace &lt;code&gt;localhost&lt;/code&gt; by the domain name or IP of your host server !&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Metaphysics - curated list</title>
      <link>/post/metaphysics-curated-list/</link>
      <pubDate>Mon, 09 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/metaphysics-curated-list/</guid>
      <description>&lt;p&gt;Metaphysics is the branch of philosophy that deals with the first principles of things, including abstract concepts such as being, knowing, identity, time, and space. This curated list of posts and videos addresses the following qurestions :&lt;/p&gt;
&lt;p&gt;&lt;em&gt;What is life ? What is a thing ? What it consciouness ? What is the true essence of reality ? Is the universe consciouss ? Are we living in a simulation ? is the Universe a quantum computer ? What is information ? Does free will exists ?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;And could quantum physics help to answer these questions ?&lt;/p&gt;
&lt;p&gt;Let‚Äôs find out ! üëá&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./post/metaphysics-curated-list_files/head-3192830_640.jpg&#34; alt=&#34;metaphysics&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;metaphysics&lt;/p&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.weforum.org/agenda/2016/11/harvard-scientists-think-they-might-have-pinpointed-the-source-of-human-consciousness/&#34;&gt;Harvard scientists think they might have pinpointed the source of human consciousness&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/d41586-018-00478-8&#34;&gt;NASA test proves pulsars can function as a celestial GPS&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://bigthink.com/paul-ratner/why-a-genius-scientist-thinks-our-consciousness-originates-at-the-quantum-level&#34;&gt;Why a ‚Äúgenius‚Äù scientist thinks our consciousness originates at the quantum level&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://waitbutwhy.com/2014/12/what-makes-you-you.html&#34;&gt;What Makes You You?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://chezfeelozof.blogspot.com/2009/06/le-demon-de-laplace.html&#34;&gt;Le D√©mon de Laplace&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://phys.org/news/2015-01-how-well-can-information-be.html&#34;&gt;How well can information be stored from the beginning to the end of time?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.pbs.org/wgbh/nova/blogs/physics/2014/04/is-information-fundamental/&#34;&gt;Is information fundamental ?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://blogs.scientificamerican.com/guest-blog/what-does-the-new-double-slit-experiment-actually-show/&#34;&gt;What Does the New Double-Slit Experiment Actually Show?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://sciencetonnante.wordpress.com/2018/04/13/lexperience-des-fentes-dyoung-en-mecanique-quantique/&#34;&gt;L‚Äôexp√©rience des fentes d‚ÄôYoung en m√©canique quantique&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.quantamagazine.org/a-new-thermodynamics-theory-of-the-origin-of-life-20140122/&#34;&gt;A New Physics Theory of Life&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://singularityhub.com/2016/06/23/elon-musk-says-were-probably-living-in-a-computer-simulation-heres-the-science/&#34;&gt;Elon Musk Says We‚Äôre Probably Living in a Computer Simulation ‚Äî Here‚Äôs the Science&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.bilan.ch/clement-javerzac-galy/vivons-une-simulation&#34;&gt;Vivons-nous dans une simulation?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.simulation-argument.com/simulation.html&#34;&gt;ARE YOU LIVING IN A COMPUTER SIMULATION?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.numerama.com/sciences/201054-vivons-nous-dans-une-simulation-elon-musk-semble-avoir-relance-le-debat.html&#34;&gt;Vivons-nous dans une simulation ? Elon Musk a relanc√© le d√©bat&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.pourlascience.fr/sd/cosmologie/vivons-nous-dans-une-simulation-informatique-12471.php&#34;&gt;Vivons-nous dans une simulation informatique ?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.scienceetfoi.com/ressources/ajustement-fin-univers-dieu/&#34;&gt;Qu‚Äôest-ce que l‚Äôajustement fin de l‚Äôunivers et en quoi pointe-t-il vers Dieu ?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://sciencetonnante.wordpress.com/2017/12/08/le-jeu-de-la-vie/&#34;&gt;Le jeu de la Vie&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://singularityhub.com/2016/08/03/we-might-live-in-a-virtual-universe-but-it-doesnt-really-matter/&#34;&gt;We Might Live in a Virtual Universe ‚Äî But It Doesn‚Äôt Really Matter&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nbcnews.com/mach/science/universe-conscious-ncna772956&#34;&gt;Is the Universe Conscious?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://bigthink.com/philip-perry/the-universe-may-be-conscious-prominent-scientists-state&#34;&gt;The universe may be conscious, say prominent scientists&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.npr.org/sections/13.7/2017/07/12/536752502/is-the-universe-conscious?t=1531036826727&#34;&gt;s The Universe Conscious?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://facethecurrent.com/culture/nassim-haramein-the-connected-universe-part-1/&#34;&gt;NASSIM HARAMEIN: THE CONNECTED UNIVERSE&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.space.com/32543-universe-a-simulation-asimov-debate.html&#34;&gt;Is the Universe a Simulation? Scientists Debate&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.express.co.uk/news/science/828324/Human-consciousness-universe-quantum-theory&#34;&gt;End of Heaven? Quantum science says you ALWAYS have existed and ALWAYS will exist&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.newscientist.com/article/mg23631510-200-consciously-quantum-how-you-make-everything-real/&#34;&gt;Consciously quantum: How you make everything real&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://cmsw.mit.edu/angles/2015/wp/is-the-universe-actually-a-giant-quantum-computer/&#34;&gt;Is the Universe Actually a Giant Quantum Computer?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=AtTTn7KMIys&amp;amp;list=PLuL1TsvlrSnddn7ddfK-eU99O5UtK640n&#34;&gt;SOMMES-NOUS DES SIMULATIONS ? L‚Äôargument de la simulation de Nick Bostrom&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=EZmvdkNjev8&amp;amp;index=2&amp;amp;list=PLuL1TsvlrSnddn7ddfK-eU99O5UtK640n&#34;&gt;IDENTIT√â PERSONNELLE (1/2) - T√©l√©portation, trous de m√©moire &amp;amp; responsabilit√©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=HPWQufM2sAg&amp;amp;index=3&amp;amp;list=PLuL1TsvlrSnddn7ddfK-eU99O5UtK640n&#34;&gt;IDENTIT√â PERSONNELLE (2/2) - Montez-vous dans le t√©l√©porteur ?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=XeZDt43Pij8&amp;amp;list=PLuL1TsvlrSnddn7ddfK-eU99O5UtK640n&amp;amp;index=4&#34;&gt;JE N‚ÄôEXISTE PAS - Grain de philo&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2FVwXaNWPQ0&#34;&gt;LA MACHINE √Ä EXP√âRIENCE de Robert Nozick&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=9-ILAnAW8us&#34;&gt;√äTES-VOUS ASSIS SUR DES √âLECTRONS ? R√©alisme scientifique&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ixbZNpgHjig&#34;&gt;O√ô DESCARTES TE MET UN GROS DOUTE&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=LgoVqA0LphY&#34;&gt;LA CHOSE QUI PENSE&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=qyDWSpX3xAk&#34;&gt;MAT√âRIALISME ET TERMINATOR&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=r-RHHrrdbfM&amp;amp;t=455s&amp;amp;index=22&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;La Conscience (avec Monsieur Phi)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nQKMNI5X148&amp;amp;t=3677s&amp;amp;index=57&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;What is Consciousness? What is Its Purpose?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=yhWG_ROulSM&amp;amp;index=68&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;If Reality Is An Illusion, Then What Is The Point of Life?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=VqULEE7eY8M&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&amp;amp;index=75&#34;&gt;The Simulation Hypothesis&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=WvXYQ1QSFV4&amp;amp;index=76&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;What Is Reality? The Human Brain - Fascinating Brain Documentary (Consciousness &amp;amp; Universe)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=w0ztlIAYTCU&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&amp;amp;index=77&#34;&gt;What Is Reality?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=5JjLpKMDw7w&#34;&gt;Quantum mechanics behind Simulation Hypothesis&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=lyu7v7nWzfo&amp;amp;t=164s&amp;amp;index=42&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;Your brain hallucinates your conscious reality&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=3WXTX0IUaOg&amp;amp;t=1s&amp;amp;index=40&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;Sir Roger Penrose ‚Äî The quantum nature of consciousness&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=GdqC2bVLesQ&amp;amp;t=0s&amp;amp;index=3&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;Measure for Measure: Quantum Physics and Reality&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4C5pq7W5yRM&amp;amp;t=171s&amp;amp;index=9&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;Quantum Physics Debunks Materialism&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=6WQ9sqIHBCA&amp;amp;t=1s&amp;amp;index=19&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;Le libre-arbitre existe-t-il ?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=rXhzeKh8yBk&amp;amp;t=0s&amp;amp;index=23&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;La Th√©orie des Cordes&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=tlTKTTt47WE&amp;amp;t=0s&amp;amp;index=45&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;Is Reality Real? The Simulation Argument&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=X9otDixAtFw&amp;amp;t=79s&amp;amp;index=43&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;What Is Something?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=JQVmkDUkZT4&amp;amp;t=93s&amp;amp;index=35&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;What Are You?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=QOCaacO8wus&amp;amp;list=PLyYuP_Fxa7MigxEn1JCvYr1AEIV1G12lK&amp;amp;t=0s&amp;amp;index=2&#34;&gt;What Is Life? Is Death Real?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=IXxZRZxafEQ&amp;amp;list=PLyYuP_Fxa7MigxEn1JCvYr1AEIV1G12lK&amp;amp;t=0s&amp;amp;index=4&#34;&gt;What Is Light?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=hOfRN0KihOU&amp;amp;list=PLyYuP_Fxa7MigxEn1JCvYr1AEIV1G12lK&amp;amp;t=1s&amp;amp;index=9&#34;&gt;How Evolution works&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=16W7c0mb-rE&amp;amp;list=PLyYuP_Fxa7MigxEn1JCvYr1AEIV1G12lK&amp;amp;t=0s&amp;amp;index=12&#34;&gt;Emergence ‚Äì How Stupid Things Become Smart Together&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=GDrBIKOR01c&amp;amp;t=0s&amp;amp;index=52&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;Messages For The Future&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=O2jkV4BsN6U&amp;amp;t=535s&amp;amp;index=51&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;Did The Past Really Happen?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=L45Q1_psDqk&amp;amp;t=404s&amp;amp;index=48&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;Is Anything Real?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=BhtgINeaJWg&amp;amp;t=19s&amp;amp;index=47&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;We Are All Related&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=sMb00lz-IfE&amp;amp;t=508s&amp;amp;index=25&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;What is NOT Random?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=zUDqI9PJpc8&amp;amp;t=7s&amp;amp;index=17&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;How Much Information?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=cebFWOlx848&amp;amp;t=142s&amp;amp;index=11&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;The Illusion of Truth&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=aIx2N-viNwY&amp;amp;t=0s&amp;amp;index=10&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;The Speed of Life&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=MBRqu0YOH14&amp;amp;t=0s&amp;amp;index=8&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;Optimistic Nihilism&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=EKR-HydGohQ&amp;amp;t=0s&amp;amp;index=7&amp;amp;list=PLyYuP_Fxa7MgpGa51dUdYyuaq-IrTOiXA&#34;&gt;Our greatest Dellusion&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Blockchain for research - curated list</title>
      <link>/post/blockchain_for_research_curated_list/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/blockchain_for_research_curated_list/</guid>
      <description>&lt;p&gt;Could blockchain :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;help science reproductibility ?&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;enhance research transparency ?&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;avoid publication fraud ?&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;enhance datasets exchanges ?&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;help to fund research projects ?&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;incentivize scientists ?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let‚Äôs find out with a few lectures !&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./post/blockchain_for_research_curated_list_files/blockchain-3277335_960_720.png&#34; /&gt;

&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.timeshighereducation.com/news/blockchain-could-help-combat-mistrust-scientific-process&#34;&gt;Blockchain ‚Äòcould help combat mistrust in scientific process‚Äô&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://cryptobriefing.com/dash-science-research-blockchain/&#34;&gt;Dash Puts Science Research On The Blockchain Academic publishing is ripe for disruption, and Dash seeks to prove a new paradigm.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.chemistryworld.com/news/blockchain-to-help-scholarly-publishing-fight-fraud/3008803.article&#34;&gt;Blockchain to help scholarly publishing fight fraud&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://medium.com/read-write-participate/concerns-about-blockchain-for-science-1540c4ac9bdb&#34;&gt;Concerns About Blockchain for Science&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.researchgate.net/publication/306107836_Blockchain_for_science_and_knowledge_creation_-_A_technical_fix_to_the_reproducibility_crisis&#34;&gt;Blockchain for science and knowledge creation - A technical fix to the reproducibility crisis ?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://blogs.scientificamerican.com/observations/many-scientific-studies-are-bogus-but-blockchain-can-help/&#34;&gt;Many Scientific Studies Are Bogus, but Blockchain Can Help&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://dataconomy.com/2017/05/blockchains-data-scientist-dream/&#34;&gt;BLOCKCHAINS COULD BE EVERY DATA SCIENTIST‚ÄôS DREAM&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://insidebigdata.com/2018/04/25/data-scientist-start-worrying-blockchain-time-soon/&#34;&gt;As a Data Scientist, Do You Have to Start Worrying About Blockchain Any Time Soon?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.blockchainforscience.com/&#34;&gt;REPRODUCIBLE RESULTS THROUGH OPENESS TO SCIENTIFIC SELF-CORRECTION. Blockchainified Science&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.sciencemag.org/news/2017/05/can-bitcoin-s-cryptographic-technology-help-save-environment&#34;&gt;Can bitcoin‚Äôs cryptographic technology help save the environment?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/d41586-017-08589-4&#34;&gt;Could Bitcoin technology help science?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://peerj.com/preprints/26496/&#34;&gt;How to harness Blockchain technology for marine conservation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Quickly create your R project directory tree with pre-filled common files</title>
      <link>/post/r-project-initializer/</link>
      <pubDate>Fri, 08 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/r-project-initializer/</guid>
      <description>&lt;p&gt;Each time you start a new R project, it is &lt;strong&gt;highly recommanded&lt;/strong&gt; to prepare a clean and &lt;a href=&#34;https://nicercode.github.io/blog/2013-05-17-organising-my-project/&#34;&gt;organized working directory&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you regularly create new projects, this working directory preparation task might seem tedious and time consuming. Creating the folders, intializing git, creating a license file, a readme file, etc.&lt;/p&gt;
&lt;p&gt;Instead of copying/pasting an existing pristine directory tree, I propose you to use the power of linux bash scripting.&lt;/p&gt;
&lt;p&gt;I‚Äôve built a little script, inspired from &lt;a href=&#34;https://frdvnw.github.io/data-sciences/linux/2018/04/12/my-r-skeletton.html&#34;&gt;frdvnw&lt;/a&gt;, that will allow you to quickly create a new R project directory tree along with all its commonly required files.&lt;/p&gt;
&lt;p&gt;So, what does the script actually do ?&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;It pulls the Github R .gitgnore template file and make it your .gitignore file&lt;/li&gt;
&lt;li&gt;It pulls the GNU GPL V3 license from gnu.org and make it your LICENSE file&lt;/li&gt;
&lt;li&gt;It pulls a default init.R script from its repo. This init.R file contains a YAML header + Terms of Services footer + my habitual R script initialization functions (load common libraries, etc‚Ä¶)&lt;/li&gt;
&lt;li&gt;It creates the tree structure (data folder, output folder, img fodlers, etc)&lt;/li&gt;
&lt;li&gt;It intialize a new git repository and make a first commit for you ;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you want to give it a try, head at its &lt;a href=&#34;https://github.com/pokyah/R-project-init&#34;&gt;repo&lt;/a&gt;, fork/clone and play it !&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to quickly create and maintain a blog with R ?</title>
      <link>/post/quickly-create-and-maintain-a-blog-with-r/</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/quickly-create-and-maintain-a-blog-with-r/</guid>
      <description>&lt;p&gt;Maintaining a blog allows you to keep track of what you have done and thought. When you don‚Äôt remember how did you succeed to find a solution to a tricky problem, browsing your old posts might help you. As a scientist, it‚Äôs also the perfect tool to communicate your results to a wider audience. Moreover it allows you to showcase your work and possibly get hired for a future project. Nowadays many tools exist for you to publish on the web. But as a R user you might be interested in a solution that seamlessly integrates with your habitual R workflow : &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;blogdown&lt;/a&gt; !&lt;/p&gt;
&lt;div id=&#34;how-to-build-your-site-using-blogdown&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to build your site using blogdown ?&lt;/h1&gt;
&lt;div id=&#34;downloading-the-necessary-stuff&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Downloading the necessary stuff&lt;/h2&gt;
&lt;p&gt;For a detailed explanation, I recommand you to read the full documentation on the blogdown official site. What would be need ? We juste need to install blogdown and &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; (a static site generator like the famous &lt;a href=&#34;https://jekyllrb.com/&#34;&gt;jekyll&lt;/a&gt;). All of this can be achieved with 3 R commands :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;blogdown&amp;quot;)
library(blogdown)
blogdown::install_hugo()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;initiating-a-new-site&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Initiating a new site&lt;/h2&gt;
&lt;p&gt;Now that we have what we need, we simply initiate a new hugo site using the followin R command :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blogdown::new_site()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Doing so will generate all the required files for your site to work. Once the command is executed, we can see our live site in action using :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blogdown::serve_site()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Woah ! Pretty neat and quick, no ? If your site looks ‚Äústrange‚Äù (no styling), you might need to edit some settings in its &lt;code&gt;config.toml&lt;/code&gt; file located at the root of your site folder. At the top of the file, replace the value of the &lt;code&gt;baseurl&lt;/code&gt; key by &lt;code&gt;&amp;quot;/&amp;quot;&lt;/code&gt; and below this line add this key-value pair :&lt;code&gt;relativeurls = true&lt;/code&gt;. Normallyh everything should now looks much more nice !&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;changing-the-parameters-of-the-site&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Changing the parameters of the site&lt;/h2&gt;
&lt;p&gt;Now in the &lt;code&gt;config.toml&lt;/code&gt; you can change the default settings like the title, authorname, etc according to your needs. You can even add new menu items. Once you are happy with your custom config, you &lt;strong&gt;must&lt;/strong&gt; delete your &lt;code&gt;public&lt;/code&gt; folder to avoid possibly conflicting git settings (you will recompile it later, once your git submodules config is done - see below) and turn your blogdown server off :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blogdown::stop_server()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;initialise-git-version-control&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Initialise git version control&lt;/h2&gt;
&lt;p&gt;As you will use &lt;a href=&#34;https://pages.github.com/&#34;&gt;github pages&lt;/a&gt; to make your website publicly available, you will need to make its root folder a git repository ((if you don‚Äôt know how to use git and github, I would recommand you to take some time to &lt;a href=&#34;http://r-bio.github.io/intro-git-rstudio/&#34;&gt;learn&lt;/a&gt; this inescapable tool for anyone who is building code). So head at &lt;a href=&#34;https://www.github.com&#34;&gt;github&lt;/a&gt; and create a new repository. This repository will hold the source files of your hugo blog and not the rendered blog (you will see why later). Once your hugo blog source files repository is created on github, you will add it as your remote repository for your local website root directory as follows :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ cd &amp;lt;LOCATION_OF_WEBSITE_ROOT_DIR&amp;gt;
$ git init
$ git remote add origin https://github.com/&amp;lt;YOUR_USERNAME&amp;gt;/&amp;lt;reponame&amp;gt;.git
$ git pull
$ git push origin master&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;publishing-your-site&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Publishing your site&lt;/h1&gt;
&lt;p&gt;Now that your sources are under version control, it‚Äôs time to make the rendered static site availble publicly. The first step is to create a special github repository that you must call &lt;code&gt;&amp;lt;YOUR_USERNAME&amp;gt;.github.io&lt;/code&gt;. Once it is created, github will treat it as a special repo and everything you will put into it will be publicly availble at &lt;code&gt;&amp;lt;YOUR_USERNAME&amp;gt;.github.io&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The second step is to add this repository as a &lt;em&gt;submodule&lt;/em&gt; of your local website root folder actually stored in a fodler called &lt;code&gt;public&lt;/code&gt; (the one yo uhave previously deleted) :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ cd &amp;lt;LOCATION_OF_WEBSITE_ROOT_DIR&amp;gt;
$ git submodule add -b master git@github.com:&amp;lt;YOUR_USERNAME&amp;gt;/&amp;lt;YOUR_USERNAME&amp;gt;.github.io.git public&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point, you can tell R blogdown to reconstruct your site under this git versioned &lt;code&gt;public&lt;/code&gt; folder :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blogdown::serve_site()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command rebuild your site in the &lt;code&gt;public&lt;/code&gt; folder and allows you to inspect it your site in the RStudio viewer.&lt;/p&gt;
&lt;p&gt;As the 2 latest commands have produced some new files, we need to commit and push these on github :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ cd &amp;lt;LOCATION_OF_WEBSITE_ROOT_DIR&amp;gt;
$ git add . 
$ git commit -m &amp;quot;adding submodule ref&amp;quot;
$ git push
$ cd &amp;lt;LOCATION_OF_WEBSITE_ROOT_DIR/public&amp;gt;
$ git add . 
$ git commit -m &amp;quot;adding rendered files&amp;quot;
$ git push&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nice ! Now you have keeped track of changes made both on your source files repo and on your rendered site repo. Wait a few seconds, and head at &lt;YOUR_USERNAME&gt;.github.io and you should see your website publicly available. Magic !&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-change-the-design-of-your-blog&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to change the design of your blog ?&lt;/h1&gt;
&lt;p&gt;If you want to change the theme of your blog, there are many ways to achieve this. I‚Äôve found the following procedure to be the most efficient one. It also uses the &lt;a href=&#34;https://git-scm.com/book/en/v2/Git-Tools-Submodules&#34;&gt;git submodules&lt;/a&gt; feature. The main idea of the procedure is to separate the versioning of your theme from the versioning of your content.&lt;/p&gt;
&lt;div id=&#34;finding-a-theme&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Finding a theme&lt;/h2&gt;
&lt;p&gt;Head at &lt;a href=&#34;https://themes.gohugo.io/&#34; class=&#34;uri&#34;&gt;https://themes.gohugo.io/&lt;/a&gt; and find the theme that best suits your tastes. Click on its ‚Äúhomepage button‚Äù, and fork the repository.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-it-to-your-website&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Adding it to your website&lt;/h2&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ cd &amp;lt;LOCATION_OF_WEBSITE_ROOT_DIR&amp;gt;
$ git submodule add -b master git@github.com:&amp;lt;YOUR_USERNAME&amp;gt;/&amp;lt;THEME_NAME&amp;gt;.github.io.git themes/&amp;lt;THEME_NAME&amp;gt; &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command has cloned your theme in the theme folder of your website. To use it, first make a backup of your &lt;code&gt;config.toml&lt;/code&gt;. Then, in your choosen theme folder, open the &lt;code&gt;exampleSite&lt;/code&gt; folder and copy paste its &lt;code&gt;config.toml&lt;/code&gt; file to your website root folder. We need to proceed this way because &lt;code&gt;config.toml&lt;/code&gt; files are theme dependent. Edit it by inspiring yourself from what was in your backed up config file.&lt;/p&gt;
&lt;p&gt;Once its done, you can ask blogdown to serve your site with its new design, commit and push both the sources and the rendered files.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tweaking-the-theme&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tweaking the theme&lt;/h2&gt;
&lt;p&gt;if you want to make changes to your theme CSS, edit its css file found in your theme‚Äôs &lt;code&gt;static&lt;/code&gt; folder. As the theme was added as a submodule you can also version it using it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;linking-files-in-your-posts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Linking files in your posts&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;./post/quickly-create-and-maintain-a-blog-with-R_files/Prostate_Cancer.csv&#34;&gt;csv example&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sources&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sources&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gohugo.io/hosting-and-deployment/hosting-on-github/&#34;&gt;Hugo Doc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Producing and mapping gridded datasets with uncertainty using R</title>
      <link>/post/gridded-uncertainty/</link>
      <pubDate>Wed, 30 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/gridded-uncertainty/</guid>
      <description>&lt;p&gt;In the context of the Agromet project, we need to produce gridded maps of temperature using data acquired by a network of 30 automatic weather stations (AWS) spatially distributed in Wallonia. To each cell, an indicator of uncertainty (i.e.¬†prediction error) must also be attached. Providing this uncertainty is of major importance because errors are not likely to be spatially homogeneous but will rather depend of the spatial arrangement of available points used to compute the model. This post will &lt;strong&gt;briefly&lt;/strong&gt; present what could be described as prediction uncertainties and how to extract these using basic R examples.&lt;/p&gt;
&lt;div id=&#34;theory-regarding-the-uncertainty&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Theory regarding the uncertainty&lt;/h2&gt;
&lt;p&gt;Model parameters are computed from a sample (the data from our AWS network in our case) to estimate the parameters of the whole population (our grid). Models actually generalize what is learnt on a sample on the whole population. So the question arises whether we can use this generalization with enough confidence (can we extrapolate these parameters to the whole population) ?&lt;/p&gt;
&lt;p&gt;To answer this question, 2 tools are commonly used :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the &lt;strong&gt;standard error&lt;/strong&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;the &lt;strong&gt;confidence interval&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The standard error is what quantifies the uncertainty while the 95% confidence intervals represent quantiles between which are found 95 % of the samples means after removing the 2.5 % of both the bigger and smaller values. A good explanation of its meaning can be found &lt;a href=&#34;https://www.mathsisfun.com/data/confidence-interval.html&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.thoughtco.com/what-is-a-confidence-interval-3126415&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the paper &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/0304380095001913&#34;&gt;&lt;em&gt;Spatial uncertainty analysis: propagation of interpolation errors in spatially distributed models&lt;/em&gt;&lt;/a&gt;, the uncertainty is depicted as the &lt;strong&gt;standard error&lt;/strong&gt; of the predictions.&lt;/p&gt;
&lt;p&gt;We can also cite the &lt;a href=&#34;http://www.irceline.be/~celinair/rio/rio_corine.pdf&#34;&gt;&lt;em&gt;Spatial interpolation of air pollution measurements using CORINE land cover data&lt;/em&gt;&lt;/a&gt; paper :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When solving the Ordinary Kriging equations, a value for the error variance can be obtained at the same time (Isaaks et al. 1989). This error variance is a measure for the uncertainty of the interpolation result&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As a reminder, here are some definitions useful to understand what the standard error exactly is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;strong&gt;standard error&lt;/strong&gt; (SE) of a statistic (usually an estimate of a parameter) is the &lt;strong&gt;standard deviation&lt;/strong&gt; of its sampling distribution.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;strong&gt;standard deviation&lt;/strong&gt; is the positive square root of the &lt;strong&gt;variance&lt;/strong&gt;. The standard deviation is expressed in the same units as the mean is, whereas the variance is expressed in squared units.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;strong&gt;variance&lt;/strong&gt; is the average squared dispersion around the mean. Variance is a measurement of the spread between numbers in a data set. The variance measures how far each number in the set is from the mean. Variance is calculated by taking the differences between each number in the set and the mean, squaring the differences (to make them positive) and dividing the sum of the squares by the number of values in the set.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-extract-the-uncertainties-of-predictions-using-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How to extract the uncertainties of predictions using R ?&lt;/h2&gt;
&lt;p&gt;Let‚Äôs find an example on the web. &lt;a href=&#34;https://scholar.google.com/citations?user=2oYU7S8AAAAJ&amp;amp;hl=en&#34;&gt;Tomislav Hengl&lt;/a&gt;, an expert in the field of geostatistics has published a nice tutorial about how to &lt;a href=&#34;http://spatial-analyst.net/wiki/index.php/Uncertainty_visualization#Visualization_of_uncertainty_using_whitening_in_R&#34;&gt;vizualize spatial uncertainty&lt;/a&gt;. In his tutorial, he uses the &lt;code&gt;se&lt;/code&gt; output of the &lt;code&gt;krige&lt;/code&gt; function as the uncertainty indicator. (&lt;a href=&#34;https://www.rdocumentation.org/packages/gstat/versions/1.1-6/topics/krige&#34;&gt;&lt;code&gt;krige&lt;/code&gt; doc&lt;/a&gt;, is a simple wrapper method around &lt;code&gt;gstat&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;). The code here below comes from his tutorial&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rgdal)
library(maptools)
library(gstat)

# using the Meuse dataset
data(meuse)
coordinates(meuse) &amp;lt;- ~x+y
data(meuse.grid)
gridded(meuse.grid) &amp;lt;- ~x+y
fullgrid(meuse.grid) &amp;lt;- TRUE

# universal kriging:
k.m &amp;lt;- fit.variogram(variogram(log(zinc)~sqrt(dist), meuse), vgm(1, &amp;quot;Sph&amp;quot;, 300, 1))
vismaps &amp;lt;- krige(log(zinc)~sqrt(dist), meuse, meuse.grid, model=k.m)
names(vismaps) &amp;lt;- c(&amp;quot;z&amp;quot;,&amp;quot;e&amp;quot;)

# Plot the predictions and the standard error :
z.plot &amp;lt;- spplot(vismaps[&amp;quot;z&amp;quot;], col.regions=bpy.colors(), scales=list(draw=TRUE), sp.layout=list(&amp;quot;sp.points&amp;quot;, pch=&amp;quot;+&amp;quot;, col=&amp;quot;black&amp;quot;, meuse))
e.plot &amp;lt;- spplot(vismaps[&amp;quot;e&amp;quot;], col.regions=bpy.colors(), scales=list(draw=TRUE))

print(z.plot, split=c(1,1,2,1), more=TRUE)
print(e.plot, split=c(2,1,2,1), more=FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./post/gridded-uncertainty_files/meuse_grid_uncertainty.png&#34; alt=&#34;Meuse data Kriging + uncertainty&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Meuse data Kriging + uncertainty&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Nice we have what we need ! Easy ! But how are SE computed for the predictions ? We could have a look at the source code of the krige function. But let‚Äôs build it manually with a simple example for the sake of comprehesion. Doing so, requires some matrix algebra (variance + covariance matrix). A detailed explanation of the next code block is available in &lt;a href=&#34;http://www.cra.wallonie.be/wp/wp-content/uploads/2016/12/Formation_Stats_3_1_GLM.pdf&#34;&gt;this course&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# example from @frdvwn

# creating a sample
set.seed(123)
n &amp;lt;- 100
n.lev &amp;lt;- 10
alpha &amp;lt;- 10
beta &amp;lt;- 1.3
sigma &amp;lt;- 4

x &amp;lt;- rep(1:n.lev,each=n/n.lev)
y &amp;lt;- alpha - beta*x + rnorm(n,0,sigma)

# vizualizing the dataset
plot(x,y)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./post/gridded-uncertainty_files/data_meuse_uncertainty.png&#34; alt=&#34;Meuse plot&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Meuse plot&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# modelizing
mod &amp;lt;- lm(y~x)

# creating the points on which we want to predict values using the model equation
X &amp;lt;- cbind(1,seq(0,10,0.01))
beta &amp;lt;- coef(mod)

# Predicting manually using matrix algebra
y.hat &amp;lt;- X %*% beta
V &amp;lt;- as.matrix(vcov(mod))
y.hat.se &amp;lt;- sqrt(diag(X %*% V %*% t(X)))

# Predicting using predict function
auto.y.hat.se &amp;lt;- predict(object = mod, newdata = data.frame(x=X[,2]), se.fit=TRUE)$se.fit

# Vizualizing the SE
plot(y~x)
lines(y.hat ~ X[,2],col=&amp;quot;red&amp;quot;)
lines(y.hat + y.hat.se ~ X[,2],col=&amp;quot;red&amp;quot;,lty=2)
lines(y.hat - y.hat.se ~ X[,2],col=&amp;quot;red&amp;quot;,lty=2)
lines(y.hat + auto.y.hat.se ~ X[,2],col=&amp;quot;green&amp;quot;,lty=2)
lines(y.hat - auto.y.hat.se ~ X[,2],col=&amp;quot;green&amp;quot;,lty=2)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./post/gridded-uncertainty_files/data_meuse_uncertainty_model.png&#34; alt=&#34;Meuse plot with SE&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Meuse plot with SE&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# same values ? 
print(head(auto.y.hat.se))

    ##         1         2         3         4         5         6 
    ## 0.7905189 0.7893898 0.7882612 0.7871330 0.7860052 0.7848779

print(head(y.hat.se))

    ##         1         2         3         4         5         6 
    ## 0.7905189 0.7893898 0.7882612 0.7871330 0.7860052 0.7848779
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok we have succeeded to manually compute the Standard errors of the predictions !&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A methodological approach to assess the best weather spatialization technique</title>
      <link>/post/methodological-approach-to-assess-the-best-spatial-interpolation-method/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/methodological-approach-to-assess-the-best-spatial-interpolation-method/</guid>
      <description>&lt;div id=&#34;context-objectives&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;1. Context &amp;amp; objectives&lt;/h1&gt;
&lt;div id=&#34;context&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.1. Context&lt;/h2&gt;
&lt;p&gt;European directive &lt;a href=&#34;http://www.eppo.int/PPPRODUCTS/information/2009_0128_EU-e.pdf&#34;&gt;2009/128/CE&lt;/a&gt; : establishing a framework for Community action to achieve the sustainable use of pesticides&lt;/p&gt;
&lt;details&gt; &lt;summary&gt;more&lt;/summary&gt;
&lt;p&gt;
&lt;!-- the above p cannot start right at the beginning of the line and is mandatory for everything else to work --&gt;
The European directive 2009/128/CE imposes member-states to set up tools that allow for a more rational use of crop protection products. Among these tools, agricultural warning systems, based on crop monitoring models for the control of pests and diseases are widely adopted and have proved their efficiency. However, due to the difficulty to get meteorological data at high spatial resolution (at the parcel scale), they still are underused. The use of geostatistical tools (Kriging, Multiple Regressions, Artificial Neural Networks, etc.) makes it possible to interpolate data provided by physical weather stations in such a way that a high spatial resolution network (mesh size of 1 km2) of virtual weather stations could be generated. That is the objective of the AGROMET project.
&lt;/p&gt;
&lt;p&gt;&lt;/details&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;objective&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.2. Objective&lt;/h2&gt;
&lt;p&gt;Provide hourly 1km¬≤ gridded datasets of weather parameters with the best accuracy (i.e.¬†spatialize hourly records from the stations on the whole area of Wallonia) = &lt;strong&gt;SPATIALIZATION&lt;/strong&gt;&lt;/p&gt;
&lt;details&gt; &lt;summary&gt;more&lt;/summary&gt;
&lt;p&gt;
&lt;!-- the above p cannot start right at the beginning of the line and is mandatory for everything else to work --&gt;
The project aims to set up an operational web-platform designed for real-time agro-meteorological data dissemination at high spatial (1km2) and temporal (hourly) resolution. To achieve the availability of data at such a high spatial resolution, we plan to ‚Äúspatialize‚Äù the real-time data sent by more than 30 connected physical weather stations belonging to the PAMESEB and RMI networks. This spatialization will then result in a gridded dataset corresponding to a network of 16 000 virtual stations uniformly spread on the whole territory of Wallonia. These ‚Äúspatialized‚Äù data will be made available through a web-platform providing interactive visualization widgets (maps, charts, tables and various indicators) and an API allowing their use on the fly, notably by agricultural warning systems providers. An extensive and precise documentation about data origin, geo-statistic algorithms used and uncertainty will also be available.
&lt;/p&gt;
&lt;p&gt;&lt;/details&gt;&lt;/p&gt;
&lt;p&gt;Best suited tools :&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;del&gt;&lt;strong&gt;physical atmospherical models&lt;/strong&gt;&lt;/del&gt; &lt;small&gt;(not straight forward to develop an explicit physical model describing how the output data can be derived from the input data) &lt;/small&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;supervised machine learning &lt;a href=&#34;https://math.stackexchange.com/questions/141381/regression-vs-classification&#34;&gt;regression&lt;/a&gt; algorithms&lt;/strong&gt; that given a set of continuous data, find the best relationship that represents the set of continuous data &lt;small&gt;(common approach largely discussed in the academic litterature)&lt;/small&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Our main goal will be to choose, for each weather parameter, the best suited supervised machine learning regression method&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;key-definitions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;2. Key definitions&lt;/h1&gt;
&lt;div id=&#34;spatialization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2.1. Spatialization&lt;/h2&gt;
&lt;p&gt;Spatialization or spatial interpolation creates a &lt;strong&gt;continuous surface&lt;/strong&gt; from values measured at discrete locations to &lt;strong&gt;predict&lt;/strong&gt; values at any location in the interest zone with the &lt;strong&gt;best accuracy&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the chapter &lt;em&gt;The principles of geostatistical analysis&lt;/em&gt; of the &lt;a href=&#34;http://dusk2.geo.orst.edu/gis/geostat_analyst.pdf&#34;&gt;Using ArcGis Geostatistical analyst&lt;/a&gt;, K. Johnston gives an efficient overview of what spatialization is and what are the two big groups of techniques (deterministic and &lt;strong&gt;stochastic&lt;/strong&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;supervised-machine-learning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2.2. Supervised machine learning&lt;/h2&gt;
&lt;p&gt;From &lt;a href=&#34;https://machinelearningmastery.com/supervised-and-unsupervised-machine-learning-algorithms/&#34;&gt;machinelearningmastery.com&lt;/a&gt; :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Supervised learning is where you have input variables (x) and an output variable (Y) and you use an algorithm to learn the mapping function from the input to the output : &lt;code&gt;Y = f(X)&lt;/code&gt;&lt;br&gt; The goal is to approximate the mapping function so well that when you have new input data (x), you can predict the output variables (Y) for that data.&lt;br&gt; It is called supervised learning because the process of an algorithm learning from the training dataset can be thought of as a teacher supervising the learning process&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Also check this worth reading &lt;a href=&#34;https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471&#34;&gt;post&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;defining-the-best-supervised-machine-learning-regression-method&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;3. Defining the best supervised machine learning regression method&lt;/h1&gt;
&lt;div id=&#34;our-general-approach&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.1. Our general approach&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Inspired from work of &lt;a href=&#34;https://github.com/pokyah/agrometeor-spatialization-review-benchmark/tree/master/assets/ZEPP&#34;&gt;ZEPP&lt;/a&gt; + &lt;a href=&#34;https://github.com/pokyah/agrometeor-spatialization-review-benchmark/tree/master/assets/arvalis&#34;&gt;Arvalis&lt;/a&gt; + &lt;a href=&#34;https://github.com/pokyah/agrometeor-spatialization-review-benchmark/tree/master/assets/IRCELINE&#34;&gt;IRCeline&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;‚Ä¶ to transpose into R-code&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;‚Ä¶ using supervised machine learning techniques&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;‚Ä¶ as proposed in the excellent &lt;a href=&#34;https://geocompr.robinlovelace.net/&#34;&gt;geocomputation with R&lt;/a&gt; book from PhD &lt;a href=&#34;http://www.robinlovelace.net/about/&#34;&gt;Robin Lovelace&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;step-by-step-workflow&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.2. Step-by-step workflow&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;From our &lt;strong&gt;historical dataset&lt;/strong&gt; of hourly weather records (&lt;a href=&#34;https://app.pameseb.be&#34;&gt;Pameseb db&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;filter a representative subset of records (e.g. &lt;strong&gt;5 years of continuous hourly records&lt;/strong&gt;) + select the ‚Äúgood‚Äù stations&lt;/li&gt;
&lt;li&gt;For &lt;strong&gt;each hourly set of records&lt;/strong&gt; (30 stations - or more (&lt;a href=&#34;https://pokyah.github.io/AWS-Humain-comparison/reporting/Humain-presentation-revealjs.html#/&#34;&gt;by integrating IRM network&lt;/a&gt;? )&lt;/li&gt;
&lt;li&gt;run a &lt;strong&gt;benchmark experiment&lt;/strong&gt; where &lt;strong&gt;different desired regression learning algorithms&lt;/strong&gt; are applied to various regression tasks (i.e.¬†datasets with different combinations of explanatory variables + the target weather parameter) with the aim to compare and rank the combinations of algorithm + used explanatory variables using a &lt;a href=&#34;https://www.researchgate.net/publication/226334863_Resampling_Strategies_for_Model_Assessment_and_Selection&#34;&gt;cross validation resampling strategy&lt;/a&gt; (LOOCV) that provides the desired &lt;a href=&#34;https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d&#34;&gt;performance metrics&lt;/a&gt; (&lt;a href=&#34;https://www.geosci-model-dev.net/7/1247/2014/gmd-7-1247-2014.pdf&#34;&gt;RMSE or MAE?&lt;/a&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Then &lt;strong&gt;aggregate, by calculating the mean&lt;/strong&gt;, all the hourly performance measures on the whole representative subset to choose the method (= regression learning algorithm + regression task) that globally performs the best&lt;/li&gt;
&lt;li&gt;For each desired hourly dataset, apply the choosen method to &lt;strong&gt;build a model&lt;/strong&gt; to make spatial predictions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use maps&lt;/strong&gt; to &lt;a href=&#34;http://spatial-analyst.net/wiki/index.php/Uncertainty_visualization#Visualization_of_uncertainty_using_whitening_in_R&#34;&gt;vizualize the predictions and their uncertainty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Make the predictions available on the platform together with its uncertainty indicator&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;workflow-activity-diagrams&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.3. workflow activity diagrams&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;./assets/uml_images/spatialization-methodology.svg&#34;&gt;spatialization methodology viewer&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;which-target-dependent-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.4. Which target dependent variables ?&lt;/h2&gt;
&lt;p&gt;‚Ä¶ or variables to be spatialized&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;temperature (a lot of litterature with expertise from KNMI + RMI)&lt;/li&gt;
&lt;li&gt;relative humidity (performed by Arvalis + ZEPP)&lt;/li&gt;
&lt;li&gt;&lt;del&gt;rainfall&lt;/del&gt; (RMI rain radar)&lt;/li&gt;
&lt;li&gt;leaves wetness (none of our partners)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;which-independent-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.5. Which independent variables ?&lt;/h2&gt;
&lt;p&gt;‚Ä¶ or explanatory variables&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;digital elevation model and its derivatives like aspect and slope (available from R command line using &lt;code&gt;getData&lt;/code&gt; from &lt;a href=&#34;https://cran.r-project.org/web/packages/raster/index.html&#34;&gt;Raster&lt;/a&gt; package)&lt;/li&gt;
&lt;li&gt;solar irradiance (available from &lt;a href=&#34;https://landsaf.ipma.pt/en/products/longwave-shortwave-radiation/dssf/&#34;&gt;eumetsat - lsa saf&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;other ? (distance to sea, CORINE land cover, temporal series, etc‚Ä¶)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;which-r-config-and-packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.6. Which R config and packages ?&lt;/h2&gt;
&lt;p&gt;In order to ensure science reproductibility (&lt;a href=&#34;https://www.sevenbridges.com/docker-based-solutions-to-reproducibility-in-science/&#34;&gt;why it is important&lt;/a&gt;), the code (&lt;a href=&#34;https://medium.com/activewizards-machine-learning-company/top-20-r-libraries-for-data-science-in-2018-infographic-956f8419f883&#34;&gt;R&lt;/a&gt;) is developed in a self-maintained and publicly available &lt;a href=&#34;https://github.com/pokyah/agrometeorDocker&#34;&gt;Docker image&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In addition to the famous &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidyverse&lt;/a&gt; packages suite, we use bleeding edge R packages :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;from sp to the new &lt;a href=&#34;https://edzer.github.io/UseR2017/&#34;&gt;sf&lt;/a&gt; (perfect integration with dplyr verbs and with the OGC &lt;a href=&#34;https://en.wikipedia.org/wiki/Simple_Features&#34;&gt;simple feature&lt;/a&gt; standard) for spatial data handling&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mlr-org.github.io&#34;&gt;mlr&lt;/a&gt; : an umbrella-package providing a unified interface to dozens of learning algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion-and-perspectives&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;4. Conclusion and perspectives&lt;/h1&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4.1. Conclusion&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Thanks to exchanges with our partners (Steering Committee and KNMI + ZEPP + Arvalis) and an extensive review (both in terms of spatial prediction theory and R-coding),&lt;/li&gt;
&lt;li&gt;we have figured out how to setup &amp;amp; code an R-facility to find the best suited interpolation method for each of our weather params&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;perspectives&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4.2. Perspectives&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;by the end of summer 2018 : benchmark of various combinations of learning algorithms &amp;amp; ancillary data&lt;/li&gt;
&lt;li&gt;you can follow the advancement of this work in progress on &lt;a href=&#34;https://github.com/pokyah/agrometeor-spatial-benchmarking&#34;&gt;github&lt;/a&gt; &lt;img src=&#34;./assets/1km-grid.png&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;colofon-an-terms-of-services&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;5. Colofon an terms of services&lt;/h1&gt;
&lt;div id=&#34;colofon&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;5.1. Colofon&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This document was generated using R software with the &lt;a href=&#34;https://deanattali.com/2015/03/24/knitrs-best-hidden-gem-spin/&#34;&gt;knitr library&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The source code of the document is availbale on &lt;a href=&#34;https://pokyah.github.io/agrometeor-methodo-spatial&#34;&gt;github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;terms-of-service&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Terms of service&lt;/h2&gt;
&lt;p&gt;To use the &lt;a href=&#34;https://app.pameseb.be/fr/pages/api_call_test/&#34;&gt;AGROMET API&lt;/a&gt; you need to provide your own user token.&lt;br /&gt;
The present script is available under the &lt;a href=&#34;https://www.gnu.org/licenses/gpl-3.0.en.html&#34;&gt;GNU-GPL V3&lt;/a&gt; license and comes with ABSOLUTELY NO WARRANTY.&lt;/p&gt;
&lt;p&gt;Copyright : Thomas Goossens - &lt;a href=&#34;mailto:t.goossens@cra.wallonie.be&#34;&gt;t.goossens@cra.wallonie.be&lt;/a&gt; 2018.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(This document was generated using &lt;a href=&#34;https://www.r-project.org/&#34;&gt;R software&lt;/a&gt; with the &lt;a href=&#34;https://deanattali.com/2015/03/24/knitrs-best-hidden-gem-spin/&#34;&gt;knitr library&lt;/a&gt;)&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A review of weather spatialization projects</title>
      <link>/post/spatialization-review/</link>
      <pubDate>Thu, 24 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/spatialization-review/</guid>
      <description>&lt;div id=&#34;introduction-and-context&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction and context&lt;/h1&gt;
&lt;p&gt;The aim of the Agromet project is to provide a near real-time hourly gridded datasets of weather parameters at the resolution of 1 km¬≤ for the whole region of Wallonia characterized by a quality indicator.&lt;/p&gt;
&lt;p&gt;The Agromet project is largely inspired by what the &lt;a href=&#34;http://www.zepp.info/&#34;&gt;ZEPP&lt;/a&gt; has developed in the context of their late blight warning services (see &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/full/10.1111/j.1365-2338.2007.01134.x&#34;&gt;academic paper&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Before starting the development of our own service, we decided to submit a survey to our end users and to perform a preliminary benchmark of weather data interpolation facilities developed by other institutions.&lt;/p&gt;
&lt;p&gt;This document compiles the useful information we have gathered during our benchmarking and synthetise the main ideas to keep in mind while building our platform.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;literature-review&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Literature review&lt;/h1&gt;
&lt;p&gt;An extensive literature review of weather spatialization techniques has been performed.&lt;/p&gt;
&lt;div id=&#34;recommanded-academic-papers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Recommanded academic papers&lt;/h2&gt;
&lt;p&gt;Here is a short selection of the most useful papers regarding the comprehension of meteorological data spatialization for our walloon agricultural context :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.snap.uaf.edu/sites/default/files/files/Interpolation_methods_for_climate_data.pdf&#34;&gt;Interpolation methods for climate data literature review - &lt;strong&gt;Sluiters&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/full/10.1111/j.1365-2338.2007.01134.x&#34;&gt;Use of geographic information systems in warning services for late blight* - &lt;strong&gt;Zeuner&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/publication/221916045_Decision_Support_Systems_in_Agriculture_Administration_of_Meteorological_Data_Use_of_Geographic_Information_SystemsGIS_and_Validation_Methods_in_Crop_Protection_Warning_Service&#34;&gt;Decision Support Systems in Agriculture: Administration of Meteorological Data, Use of Geographic Information Systems(GIS) and Validation Methods in Crop Protection Warning Service - &lt;strong&gt;Racca&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S1352231008001829&#34;&gt;Spatial interpolation of air pollution measurements using CORINE land cover data - &lt;strong&gt;Janssen&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/publication/6720140_Spatial_interpolation_of_ambient_ozone_concentrations_from_sparse_monitoring_points_in_Belgium&#34;&gt;Spatial interpolation of ambient ozone concentrations from sparse monitoring points in Belgium - &lt;strong&gt;Hooyberghs&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/publication/281538637_The_Developments_in_Spatialization_of_Meteorological_and_Climatological_Elements&#34;&gt;The developments in spatialization of meteorological and climatological elements - &lt;strong&gt;Tveito&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0168192304001443&#34;&gt;Solar irradiance-corrected spatial interpolation of hourly temperature in complex terrain - &lt;strong&gt;Journ√©e&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the coming months we plan to organize and share our full bibliography.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reference-books&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reference books&lt;/h2&gt;
&lt;p&gt;These books focus on the theory relative to the general principles of spatialization techniques :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.muthar-alomar.com/wp-content/uploads/2013/01/Spatial-Interpolation_for-Climate.pdf&#34;&gt;Spatial Interpolation for Climate Data - The Use of GIS in Climatology and Meteorology - &lt;strong&gt;Dyras&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.itc.nl/library/papers_2009/general/PrinciplesGIS.pdf&#34;&gt;Principles of Geographic Information Systems - An introductory textbook - &lt;strong&gt;Huisman&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.downloadreferencebook.com/download/principles-of-geographical-information-systems&#34;&gt;Principles Of Geographical Information Systems - &lt;strong&gt;Burrough&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://xa.yimg.com/kq/groups/17314041/411653630/name/ESRI%20-%20Using%20ArcGIS%20Geostatistical%20Analyst.pdf&#34;&gt;Using ArcGIS Geostatistical Analyst - &lt;strong&gt;Johnston&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://corpdata.s3.amazonaws.com/68229/Rec2008_023.pdf&#34;&gt;A review of spatial interpolation methods for environmental scientists - &lt;strong&gt;Li&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://spatial-analyst.net/book/system/files/Hengl_2009_GEOSTATe2c0w.pdf&#34;&gt;A Practical Guide to Geostatistical Mapping of Environmental Variables - &lt;strong&gt;Hengl&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;european-experts-in-weather-data-spatialization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;European experts in weather data spatialization&lt;/h2&gt;
&lt;p&gt;Here is a list of european experts in terms of weather spatialization worth following.&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;4%&#34; /&gt;
&lt;col width=&#34;10%&#34; /&gt;
&lt;col width=&#34;21%&#34; /&gt;
&lt;col width=&#34;63%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Country&lt;/th&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;Institution&lt;/th&gt;
&lt;th&gt;Publication&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Allemagne&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/researcher/2067858955_T_Zeuner&#34; title=&#34;T. Zeuner&#34;&gt;T. Zeuner&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;ZEPP German Crop Protection Services&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1111/j.1365-2338.2007.01134.x/abstract&#34; title=&#34;Use of geographic information systems in warning services for late blight&#34;&gt;Use of geographic information systems in warning services for late blight&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Serbie&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Milan_Kilibarda&#34; title=&#34;Milan Kilibarda&#34;&gt;Milan Kilibarda&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;University of Belgrade&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1002/2013JD020803/full&#34; title=&#34;Spatio-temporal interpolation of daily temperatures for global land areas at 1 km resolution&#34;&gt;Spatio-temporal interpolation of daily temperatures for global land areas at 1 km resolution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Pays-bas&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Raymond_Sluiter&#34; title=&#34;Raymond Sluiter&#34;&gt;Raymond Sluiter&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;KNMI&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://bibliotheek.knmi.nl/knmipubIR/IR2009-04.pdf&#34; title=&#34;Interpolation methods for climate data - literature Review&#34;&gt;Interpolation methods for climate data - literature Review&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Pays-bas&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Tomislav_Hengl/info&#34; title=&#34;Tomislav Hengl&#34;&gt;Tomislav Hengl&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;ISRIC World Soil Information Institute&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://spatial-analyst.net/&#34; title=&#34;R-package Spatial Analyst&#34;&gt;R-package Spatial Analyst&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Norwegian&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Jean_Marie_Lepioufle2&#34; title=&#34;Jean-Marie Lepioufle&#34;&gt;Jean-Marie Lepioufle&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Norwegian Meteorological Institute&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Cristian_Lussana/publication/273490969_Recent_developments_in_spatial_interpolation_of_precipitation_and_temperature_at_MET_Norway/links/5795e56b08ae33e89facf86c/Recent-developments-in-spatial-interpolation-of-precipitation-and-temperature-at-MET-Norway.pdf?origin=publication_detail&amp;amp;ev=pub_int_prw_xdl&amp;amp;msrp=a_HsvemfIRpbbqok3OlrTe8W9s_6vi8bVNvdjephGEA2_k9Suwd0IUkjixOkL5r5jXh_oXKkzI389swr4tejguYvbA-0zorY72HaBur5WoU.5fBXmB2tkhX9yQfUWqB0dmFQjoHHkZWdTyFSeW_aeJilRXS_mvei-gj8CwU4R35LAY5De9xxW_E24VSGd3Z_GA.SH190BKK4lOgQzKG58PawvoInnZohck8jBvlJZjWcz-B3kVG2Ve1myuXcYtnLVMrsPNHqR9BrT8jAZuxD9oeKw.jn9JyplYcwA7xW0lx6Me8ZFBjvOCKR-cXndTvljnxwFnf9BRoJs1xBIjii81yczJmd5mdN501yE-GKYD5mxoNw&#34; title=&#34;Recent developments in spatial interpolation of precipitation and temperature at MET Norway&#34;&gt;Recent developments in spatial interpolation of precipitation and temperature at MET Norway&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Gr√®ce&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Kostas_Philippopoulos&#34; title=&#34;Kostas philippopoulos&#34;&gt;Kostas philippopoulos&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;University of Reading&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/publication/269279018_Artificial_Neural_Network_Modeling_of_Relative_Humidity_and_Air_Temperature_Spatial_and_Temporal_Distributions_Over_Complex_Terrains&#34; title=&#34;Artificial Neural Network Modeling of Relative Humidity and Air Temperature Spatial and Temporal Distributions Over Complex Terrains&#34;&gt;Artificial Neural Network Modeling of Relative Humidity and Air Temperature Spatial and Temporal Distributions Over Complex Terrains&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Portugual&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Alvaro_Silva13&#34;&gt;Silva Alvaro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Instituto Portugu√™s do Mar e da Atmosfera&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/publication/276058549_Neural_Networks_application_to_spatial_interpolation_of_climate_variables&#34; title=&#34;Neural Networks application to spatial interpolation of climate variables&#34;&gt;Neural Networks application to spatial interpolation of climate variables&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Slov√©nie&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Luka_Honzak&#34; title=&#34;Luka honzak&#34;&gt;Luka honzak&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Bo Mo LTD&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://www.bo-mo.si/fispace/&#34; title=&#34;WEATHER SCENARIO APP&#34;&gt;WEATHER SCENARIO APP&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;France&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Mehdi_Sine&#34; title=&#34;Mehdi Sine&#34;&gt;Mehdi Sine&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Vigicultures par Arvalis - institut du V√©g√©tal&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/publication/230838280_VIGICULTURES_-_An_early_warning_system_for_crop_pest_management&#34; title=&#34;VIGICULTURES ‚Äì An early warning system for crop pest management&#34;&gt;VIGICULTURES ‚Äì An early warning system for crop pest management&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Belgique&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Aurore_Degre&#34; title=&#34;Aurore Degr√©&#34;&gt;Aurore Degr√©&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Facult√© Gemboux&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://popups.ulg.ac.be/1780-4507/index.php?id=10003&#34; title=&#34;Different methods for spatial interpolation of rainfall data for operational hydrology and hydrological modeling at watershed scale: a review&#34;&gt;Different methods for spatial interpolation of rainfall data for operational hydrology and hydrological modeling at watershed scale: a review&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Pologne&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Maciej_Kryza&#34; title=&#34;Maciej Kryza&#34;&gt;Maciej Kryza&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;university de Wroclaw&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;key-learnings-from-the-review&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Key learnings from the review&lt;/h2&gt;
&lt;p&gt;The literature reveals that a lot of spatial interpolation methods have been developed the last decades. These techniques have been borrowed from other fields and transposed (oil prospection) in the field of meteorology where the comprehension and modelisation of the processes is much more technical due to the complexity and the spatial heterogeneity of weather events. In such, there is not an out-of-the box recipe to apply to each weather parameter.&lt;/p&gt;
&lt;p&gt;The choice of the right interpolation method depends of many factors such as the spatial distribution of the weather station network, the topography, the number of stations, local gradients such as global circulation effects, etc. Moreover, more attention has been ported on the spatialization of &lt;strong&gt;climate&lt;/strong&gt; data rather than &lt;strong&gt;hourly meteorological&lt;/strong&gt; data which is our concern. Therefore, an important phase of testing, benchmarking and tweaking of the processes described here above is required in order to efficiently produce useful and sensible gridded outputs that could be used profitably by agronomical models.&lt;/p&gt;
&lt;p&gt;These phase will require a deep knowledge of the principles of these geostatistical spatialization method combined with the development of programming skills required to explore the data and conduct practical analysis. The exploratory phases needed for the development of an adjusted data analysis technique able to deal with data scarcity should be performed in a way such as the the most simple solutions are evaluated first. Depending of the results of the evaluation of the investigated technique, we will decide if further investigations are required. If no significant extra-value is added by are more complex process, the later will not be retained.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-and-automatic-weather-stations-aws-networks-knowledge&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data and Automatic Weather Stations (AWS) networks knowledge&lt;/h1&gt;
&lt;p&gt;A specific attention will be ported on the analysis of the quality of the data produced by each of our stations. We will need to carry an analysis in order to detect eventual structural or local effects such as overheating in temperature shelters.&lt;/p&gt;
&lt;p&gt;It is important to get a deep insight and comprehensive overview of our weather station network before interpolating its data in order to avoid the integration of non-desired local or structural effects during the interpolation process. Local temperature effects will be detectable by pointing out abnormally high our low values appearing from long term analysis of each of the stations from our network.&lt;/p&gt;
&lt;p&gt;Again, a good knowledge of the station network (eg : situation and direct environment of each of the stations) is required. To remove local effects from the interpolation process, each station could first be weighted according to a quality parameter characterized by the local situation of the considered station. Time series analysis ( &lt;a href=&#34;https://pokyah.github.io/pokyah-maps/temperature/&#34;&gt;example map&lt;/a&gt; ) will help us for this purpose.&lt;/p&gt;
&lt;p&gt;The Agromet project will spatialize weather data gathered both by the &lt;a href=&#34;https://www.pameseb.be/&#34;&gt;Pameseb&lt;/a&gt; network own by the &lt;a href=&#34;http://www.cra.wallonie.be/fr&#34;&gt;CRA-W&lt;/a&gt; and stations owned by the national weather office &lt;a href=&#34;https://www.meteo.be&#34;&gt;RMI&lt;/a&gt;. Before integrating two different networks in the spatilization process, we need to assess their intercompatibilty. To address this, both our team and the RMI works on an intercomparison of the networks performed by the mean of a location (Humain - Belgium) equiped with 2 stations belongings to the 2 networks. The first results of this comparative analysis are available on &lt;a href=&#34;https://pokyah.github.io/AWS-Humain-comparison/&#34;&gt;this repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first results suggest that for the temperature, we will need to apply a correction model to the Pameseb measurments recorded around the daily maximal temperature hours.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;understanding-our-end-users-needs&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Understanding our end-users needs&lt;/h1&gt;
&lt;p&gt;A web-survey has been submitted to our potential end-users. Its purpose was to insure that the platform integrates the real needs of the future end-users (walloon crop warning system managers and academic research). The results of this survey also serve as a development priority list. The results are available in this &lt;a href=&#34;../assets/survey/report_end-users-survey.pdf&#34;&gt;report&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;audit-of-an-external-spatialized-weather-data-provider&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Audit of an external spatialized weather data provider&lt;/h1&gt;
&lt;p&gt;The Weather Company (owned by IBM) provides hourly gridded dataset at the resolution of 1 km¬≤. Using their solution would allow us to rapidly provide a functional platform. However, the inherent costs of the use of a third party provider and the lack of transparency regarding how the spatialization process works and performs do not allow us to choose this solution.&lt;/p&gt;
&lt;p&gt;As a research institution, it is also our role to develop expertise in various fields like weather data spatialization and to make this expertise valuable to our clients (the walloon farmers). Its is also worth to keep in mind that developping our own platform is an excellent way to value the Pameseb AWS network.&lt;/p&gt;
&lt;p&gt;For the complete solution proposed by IBM, please refer to the &lt;a href=&#34;./spatialization-review-files/IBM/&#34;&gt;IBM supplementary material&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exchanges-with-our-partners&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Exchanges with our partners&lt;/h1&gt;
&lt;p&gt;Here we present the key learnings from the experience feedbacks of the various institutions we have met during our benchmarking campain.&lt;/p&gt;
&lt;div id=&#34;knmi---netherlands&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;KNMI - Netherlands&lt;/h2&gt;
&lt;p&gt;The KNMI (KONINKELIJK NATIONAAL METEOROLOGISCH INSTITUUT) has developed what they call &lt;a href=&#34;../assets/DailyMeteo2014_Sluiter_20140627_002s.pdf&#34;&gt;An operational R-based interpolation facility for climate and meteo data&lt;/a&gt;. In october 2017 we have organized a first knowledge exchange workshop with this partner.&lt;/p&gt;
&lt;p&gt;They have found R-software to be the most appropriate tool for weather data spatialization. This opinion is also shared by Meteo Switzerland (Christopher Frei), Meteo Norway (Ole Einar Tveito) and the RMI (Michel Journ√©e).&lt;/p&gt;
&lt;p&gt;Raymond Sluiter has published the review paper &lt;a href=&#34;https://www.researchgate.net/publication/242783501_Interpolation_methods_for_climate_data&#34;&gt;Interpolation methods for climate data&lt;/a&gt; into which he details the various deterministic and stochastic spatilization methods available. This review is an excellent starting point for who wants to start in the field of weather data spatialization.&lt;/p&gt;
&lt;p&gt;Their developments were conducted in the context of the creation of a new climate atlas rather than with agronomical purposes. According to their feedback, there is no out-of-the box solution. We must find the solution best suited to our purpose by proceeding from the simplest solution and progressively add more complexity while asserting the level of accuracy brougth by this additional complexity. A good balance must be found between complexity and operability since we aim to build an operational suite.&lt;/p&gt;
&lt;p&gt;Their presentations are available in the &lt;a href=&#34;../assets/KNMI/&#34;&gt;KNMI supplementary materials&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;arvalis---france&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Arvalis - France&lt;/h2&gt;
&lt;p&gt;Arvalis (Institut du V√©g√©tal) has also conducted weather data spatialization research in an agricultural context (crop warning systems). We have organized a knowledge exchange workshop in January 2018. Like the KNMI they have tested various methods with an increasing level of complexity. Our contact Olivier Deudon also uses R-software to conduct his researches.&lt;/p&gt;
&lt;p&gt;The key points of their research are detailed in the &lt;a href=&#34;../assets/arvalis/&#34;&gt;arvalis supplementary materials&lt;/a&gt;. Here we present a brief summary of their methodology and main findings. The aim of their work was to test various methods of weather data spatial interpolation and find the most efficient ones (in terms of accuracy) for various parameters (temperature, relative humidity, rainfall) in the context of their specific AWS network (&amp;gt; 400 stations in France).&lt;/p&gt;
&lt;p&gt;Regarding temperature :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tested methods : Inverse distance, multiple regressions, various kriging methods&lt;/li&gt;
&lt;li&gt;validation method : splitting the dataset in training set (355 stations) and test set (100 stations)&lt;/li&gt;
&lt;li&gt;model evaluation criterion : RMSE&lt;/li&gt;
&lt;li&gt;method with the lowest RMSE for T¬∞: universal kriging&lt;/li&gt;
&lt;li&gt;used covariates : elevation, surface solar irradiance&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;zepp---germany&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;ZEPP - Germany&lt;/h2&gt;
&lt;p&gt;As mentioned above, our project is mainly inspired from the ZEPP (ZENTRALSTELLE DER L√ÑNDER F√úR EDV-GEST√úTZTE ENTSCHEIDUNGSHILFEN UND PROGRAMME IM PFLANZENSCHUTZ - &lt;em&gt;Central Institute for Decision Support Systems in Crop Protection&lt;/em&gt;) work. Here we present the key points of our November 2017 workshop.&lt;/p&gt;
&lt;p&gt;It is essential to keep in mind the agricultural scope of the platform. The objective is make the best predictions &lt;strong&gt;in cultural area&lt;/strong&gt;. It is not a problem if the quality of the prediction is not as high in area were not crops are grown (e.g.¬†Hautes-Fagnes).&lt;/p&gt;
&lt;p&gt;What matters most are the quality of the decision support tools outputs based on our weather data rather than the weather data itself. Their comparison of various spatialization technique revealed that for their needs, the most efficient technique is the multiple regression based on elevation, latitude and longitude. This comparison is extensively discussed in the Zeuner PhD Thesis present in the &lt;a href=&#34;../assets/ZEPP/&#34;&gt;ZEPP supplementary material&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here we present a brief summary of their method and main findings. The aim of their work was to provide an operationnal platform able to supply crop alert system models with hourly gridded datasets of temperature and relative humidity accross germany that present the highest accuracy.&lt;/p&gt;
&lt;p&gt;Regarding temperature :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tested methods : krigin, IDW, spline, multiple regression&lt;/li&gt;
&lt;li&gt;validation method : 570 stations&lt;/li&gt;
&lt;li&gt;model evaluation criterion: difference hourly interpolated - measured at the location of the stations (+ boxplots)&lt;/li&gt;
&lt;li&gt;used covaraites : elevation&lt;/li&gt;
&lt;li&gt;choosen method : multiple regression&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;rmi---royal-meteorological-institute---belgium&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;RMI - Royal Meteorological Institute - Belgium&lt;/h2&gt;
&lt;p&gt;The RMI is our primary partner in terms of weather data spatialization with who we work in close collaboration. As the KNMI, they have an advanced expertise in terms of spatialization of weather data using R software.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;../assets/IRM/&#34;&gt;RMI supplementary material&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;choosing-the-right-software&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Choosing the right software&lt;/h1&gt;
&lt;p&gt;Among all the available programming languages, we choose &lt;a href=&#34;https://www.r-project.org/&#34; title=&#34;R&#34;&gt;R&lt;/a&gt; : - Fully &lt;a href=&#34;https://www.wired.com/2013/09/why-free-software-is-more-important-now-than-ever-before/&#34;&gt;open-source and free (like beer and freedom)&lt;/a&gt; - large user base and &lt;a href=&#34;https://thenextweb.com/offers/2018/03/28/tech-giants-are-harnessing-r-programming-learn-it-and-get-hired-with-this-complete-training-bundle/&#34;&gt;more and more used&lt;/a&gt; - R is developed by statisticians for statisticians - R is already used by other institutions implicated in weather data spatialization and internally at CRA-W - Many libraries (packages) cover our needs&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;32%&#34; /&gt;
&lt;col width=&#34;67%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;package&lt;/th&gt;
&lt;th&gt;purpose&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/gstat/index.html&#34; title=&#34;gstat&#34;&gt;gstat&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Spatial and Spatio-Temporal Geostatistical Modelling, Prediction and Simulation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/meteo/index.html&#34; title=&#34;meteo&#34;&gt;meteo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Spatio-Temporal Analysis and Mapping of Meteorological Observations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/sf/index.html&#34; title=&#34;sf&#34;&gt;sf&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Simple Features for R&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/raster/index.html&#34; title=&#34;raster&#34;&gt;raster&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Geographic Data Analysis and Modeling&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/automap/index.html&#34; title=&#34;automap&#34;&gt;automap&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Automatic interpolation package&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/dplyr/index.html&#34; title=&#34;dplyr&#34;&gt;dplyr&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A Grammar of Data Manipulation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/rgdal/index.html&#34; title=&#34;rgdal&#34;&gt;rgdal&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Bindings for the Geospatial Data Abstraction Library&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/ggplot2/index.html&#34; title=&#34;ggplot2&#34;&gt;ggplot2&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Create Elegant Data Visualisations Using the Grammar of Graphics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/shiny/index.html&#34; title=&#34;shiny&#34;&gt;shiny&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Web Application Framework for R&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/geoR/index.html&#34; title=&#34;geoR&#34;&gt;geoR&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Analysis of Geostatistical Data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/validate/index.html&#34; title=&#34;validate&#34;&gt;validate&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Data Validation Infrastructure&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/mlr/index.html&#34; title=&#34;mlr&#34;&gt;mlr&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Machine Learning in R&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here is an &lt;a href=&#34;https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis#gs.9_Pvc14&#34;&gt;infography&lt;/a&gt; that compares R to python.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;extra-investigations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Extra investigations&lt;/h1&gt;
&lt;p&gt;If extra time remains, we could investigate to incorporate crowdsourced datasets. At the present time, both the KNMI and the RMI work on such a process in the context of the &lt;a href=&#34;http://wow.metoffice.gov.uk&#34;&gt;WOW experiment&lt;/a&gt; initiated by the UK metoffice.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-dissemination-policy&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data dissemination policy&lt;/h1&gt;
&lt;p&gt;A particular attention will be given to make our data &lt;a href=&#34;https://inspire.ec.europa.eu/&#34;&gt;INSPIRE&lt;/a&gt; compliant and their origin will be described using the &lt;a href=&#34;https://www.w3.org/TR/prov-dm/&#34;&gt;W3C recommandations&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As developers we push for the adoption of an open-data policy as the &lt;a href=&#34;https://cdla.io/&#34;&gt;Community Data License Agreement&lt;/a&gt;. However, the final decision regarding the choice of the policy will be taken at higher levels.&lt;/p&gt;
&lt;p&gt;Here is a selection of publications in agreement with an open-data approach :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002598&#34;&gt;open-source software in sciences paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://data.knmi.nl/services&#34;&gt;KNMI data policy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ec.europa.eu/programmes/horizon2020/en/h2020-section/open-science-open-access&#34;&gt;Eu general principle for open access to scientific publications in Horizon 2020&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://be.brussels/files-fr/a-propos-de-la-region/mrbc/lopen-data-et-les-administrations-en-rbc&#34;&gt;Brussels administrations and open data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://data.gov.be/fr/news/strategie-federale-open-data&#34;&gt;Belgian federal state and open data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalwallonia.be/open-big-data-as-a-service/&#34;&gt;Wallonia and open data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cointelegraph.com/news/the-open-source-world-is-worth-billions&#34;&gt;The value of open source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://bollier.org/blog/bauwens-use-peer-production-license-foster-%E2%80%9Copen-cooperativism%E2%80%9D&#34;&gt;Open-source et cooperativism&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Spatial interpolation using multiple linear regression : a beginners&#39;s overview (R implementation)</title>
      <link>/post/spatial-interpolation-using-multiple-linear-regression-a-beginners-overview-r-implementation/</link>
      <pubDate>Tue, 03 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/spatial-interpolation-using-multiple-linear-regression-a-beginners-overview-r-implementation/</guid>
      <description>&lt;p&gt;The AGROMET Project lead by the Walloon agricultural research center (&lt;a href=&#34;http://www.cra.wallonie.be/fr&#34;&gt;CRA-W&lt;/a&gt;) requires to generate spatialized weather dataset. In this context, multiple spatialization methods will be tested and evaluated among which the &lt;strong&gt;multiple regression&lt;/strong&gt; technique. This post provides an introductory material to the multiple regression modeling technique applied to spatial data. It is not a tutorial and it is rather aimed at paving the way for beginners who want to take their first steps into in the field of applied geostatistics (with R) by defining key concepts and providing a lot of external resources worth reading !&lt;/p&gt;
&lt;details&gt; &lt;summary&gt;Full details about the AGROMET project&lt;/summary&gt;
&lt;p&gt;
&lt;!-- the above p cannot start right at the beginning of the line and is mandatory for everything else to work --&gt;
&lt;h3&gt;
Context
&lt;/h3&gt;
&lt;p&gt;The European directive 2009/128/CE imposes member-states to set up tools that allow for a more rational use of crop protection products. Among these tools, agricultural warning systems, based on crop monitoring models for the control of pests and diseases are widely adopted and have proved their efficiency. However, due to the difficulty to get meteorological data at high spatial resolution (at the parcel scale), they still are underused. The use of geostatistical tools (Kriging, Multiple Regressions, Artificial Neural Networks, etc.) makes it possible to interpolate data provided by physical weather stations in such a way that a high spatial resolution network (mesh size of 1 km2) of virtual weather stations could be generated. That is the objective of the AGROMET project. &lt;br&gt;&lt;/p&gt;
&lt;h3&gt;
Objectives
&lt;/h3&gt;
&lt;p&gt;The project aims to set up an operational web-platform designed for real-time agro-meteorological data dissemination at high spatial (1km2) and temporal (hourly) resolution. To achieve the availability of data at such a high spatial resolution, we plan to ‚Äúspatialize‚Äù the real-time data sent by more than 30 connected physical weather stations belonging to the PAMESEB and RMI networks. This spatialization will then result in a gridded dataset corresponding to a network of 16 000 virtual stations uniformly spread on the whole territory of Wallonia. These ‚Äúspatialized‚Äù data will be made available through a web-platform providing interactive visualization widgets (maps, charts, tables and various indicators) and an API allowing their use on the fly, notably by agricultural warning systems providers. An extensive and precise documentation about data origin, geo-statistic algorithms used and uncertainty will also be available.&lt;/p&gt;
&lt;/p&gt;
&lt;p&gt;&lt;/details&gt;&lt;/p&gt;
&lt;div id=&#34;spatialization-definition&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Spatialization definition&lt;/h2&gt;
&lt;p&gt;Spatialization or spatial interpolation creates a &lt;strong&gt;continuous surface&lt;/strong&gt; from values measured at discrete locations to predict values at any location in the interest zone with the best accuracy. Characterizing the error and the variability of the predicted data are also parts of spatialization procedures.&lt;/p&gt;
&lt;p&gt;In the chapter &lt;em&gt;The principles of geostatistical analysis&lt;/em&gt; of the &lt;a href=&#34;http://dusk2.geo.orst.edu/gis/geostat_analyst.pdf&#34;&gt;Using ArcGis Geostatistical analyst&lt;/a&gt;, K. Johnston gives an efficient overview of what spatialization is and what are the two big groups of techniques (deterministic and stochastic).&lt;/p&gt;
&lt;p&gt;We will not present all of them in the context of this post to keep the focus on the multiple regression technique.&lt;/p&gt;
&lt;p&gt;(&lt;em&gt;The book also provides a glossary of recurrent geostatistical terms (another useful one is available on Pr. D.E. Meyers &lt;a href=&#34;http://www.u.arizona.edu/~donaldm/homepage/glossary.html&#34;&gt;personal page&lt;/a&gt;&lt;/em&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-linear-regression-key-concept&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiple linear Regression : key concept&lt;/h2&gt;
&lt;p&gt;No need to reinvent the wheel, let‚Äôs borrow 3 definitions found in the literature :&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;From Selva Prabhakaran‚Äôs &lt;a href=&#34;http://r-statistics.co/Linear-Regression.html&#34;&gt;r-statistics.co site&lt;/a&gt; :&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ÄúLinear regression is used to predict the value of an outcome variable Y based on one or more input predictor variables X. The aim is to establish a linear relationship (a mathematical formula) between the predictor variable(s) and the response variable, so that, we can use this formula to estimate the value of the response Y, when only the predictors (Xs) values are known.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;In his comprehensive &lt;a href=&#34;https://www.snap.uaf.edu/sites/default/files/files/Interpolation_methods_for_climate_data.pdf&#34;&gt;litterature review&lt;/a&gt;, R. Sluiters from the &lt;a href=&#34;http://www.knmi.nl/home&#34;&gt;KNMI&lt;/a&gt; defines multiple regression as follows :&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ÄúLinear regression expresses the relation between a predicted variable and one or more explanatory variables. In its simples form a straight line is fitted through the data points. Linear regression models are most often global interpolators. Linear regression models are deterministic, but by considering some statistical assumptions about the probability distribution of the predicted variable the method becomes stochastic. In that case the standard error can be calculated, the inference about the regression parameter and the predicted values can be assessed and the prediction accuracy can be calculated. For deterministic linear regression models the assumption is that the regression model could be interpreted on the basis of physical reasons, for stochastic linear regression models a normal distribution and spatial independence is also assumed. No extrapolations are allowed from the theoretical perspective. Ancillary data can be included using multiple regression. For deterministic linear regression models the measure of success is through cross validation. For stochastic linear regression models it can be measured by the explained variance and the regression standard error.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;In their paper (from which the Agromet project was inspired) &lt;em&gt;Decision Support Systems in Agriculture: Administration of Meteorological Data, Use of Geographic Information Systems(GIS) and Validation Methods in Crop Protection Warning Service&lt;/em&gt;, &lt;a href=&#34;https://www.intechopen.com/books/efficient-decision-support-systems-practice-and-challenges-from-current-to-future/decision-support-systems-in-agriculture-administration-of-meteorological-data-use-of-geographic-info&#34;&gt;Racca et al. 2011&lt;/a&gt; present multiple regression in these terms:&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ÄúThe general purpose of multiple regressions (the term was first used by Pearson, 1908) is to learn more about the relationship between several independent or predictor variables and a dependent or criterion variable. MR is an interpolation method that allows simultaneous testing and modeling of multiple independent variables (Cohen, et al., 2003). Parameters that have an influence on temperature and relative humidity, e.g.¬†elevation, slope, aspect, can therefore be tested simultaneously.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(&lt;em&gt;In this paper, the authors also briefly present why the Multiple Regression technique was chosen over other modeling techniques. A more detailed explanation of the comparative study between the various techniques is available in the companion paper by &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2338.2007.01134.x&#34;&gt;Zeuner et. 2007&lt;/a&gt;&lt;/em&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-prediction-using-multiple-linear-regression-workflow&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data prediction using multiple linear regression : workflow&lt;/h2&gt;
&lt;div id=&#34;building-the-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Building the model&lt;/h3&gt;
&lt;p&gt;In &lt;a href=&#34;https://machinelearningmastery.com/supervised-and-unsupervised-machine-learning-algorithms/&#34;&gt;Supervised machine learning&lt;/a&gt;, the response variable is modeled as a function of predictors. To build the model you will need to construct a dataset made of predictors (e.g.¬†elevation, latitude, longitude, soil occupation, aspect) and response variable (e.g.¬†temperature, humidity, rainfall). You will most likely also need to inspect and clean your dataset (e.g.¬†removing outliers, check for errors, treat any missing values) before building the model :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Garbage_in,_garbage_out&#34;&gt;Garbage in, garbage out&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Once your dataset is prepared you can build your regression model. Each data-analysis software provides a set of functions to build such a kind of model (in R you do it with the &lt;code&gt;lm()&lt;/code&gt; function).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluating-the-model---linear-regression-diagnostics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluating the model - Linear Regression Diagnostics&lt;/h3&gt;
&lt;p&gt;Once the linear model is fitted, the mathematical formula to predict the response variable is obtained. However it is not enough to actually use this model ! Before using a regression model, you have to ensure that it is &lt;strong&gt;statistically significant&lt;/strong&gt;. There are many indicators that you can use to evaluate the validity of a regression model, among which :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Residual plot&lt;/li&gt;
&lt;li&gt;Goodness of fit&lt;/li&gt;
&lt;li&gt;Standard error of the regression&lt;/li&gt;
&lt;li&gt;p-value&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To get a deep insight of these model diagnostic indicators, check these 2 excellent R-oriented posts about evaluating regression model outputs by &lt;a href=&#34;https://feliperego.github.io/blog/2015/10/23/Interpreting-Model-Output-In-R&#34;&gt;Felipe Rego&lt;/a&gt; and &lt;a href=&#34;http://r-statistics.co/Linear-Regression.html&#34;&gt;Selva Prabhakaran&lt;/a&gt;. You can also have a quick look at this &lt;a href=&#34;https://www.otexts.org/fpp/4/4&#34;&gt;page&lt;/a&gt;. You may also have a look at the Minitab‚Äôs blog posts (&lt;a href=&#34;http://blog.minitab.com/blog/adventures-in-statistics-2/multiple-regession-analysis-use-adjusted-r-squared-and-predicted-r-squared-to-include-the-correct-number-of-variables&#34;&gt;1&lt;/a&gt;, &lt;a href=&#34;http://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit&#34;&gt;2&lt;/a&gt; concerning the interpretation of the R¬≤ values&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-model-and-measuring-its-success-i.e.validation-process&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using the model and measuring its success (i.e.¬†validation process)&lt;/h3&gt;
&lt;p&gt;Now that you have tested the validity of your model (i.e.¬†your model is statistically significant), you can use it to make some predictions. But an important question then arises : how well your model performs at predicting the data at unknown locations ? To answer this question, you need to rigorously test your model performance as much as possible. This is done using a &lt;strong&gt;cross-validation&lt;/strong&gt; (CV) process.&lt;/p&gt;
&lt;p&gt;From Robin Lovelace‚Äôs &lt;em&gt;Geocomputation with R&lt;/em&gt; &lt;a href=&#34;https://geocompr.robinlovelace.net/spatial-cv.html&#34;&gt;book&lt;/a&gt; :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;CV determines a model‚Äôs ability to predict new data or differently put its ability to generalize. To achieve this, CV splits a dataset (repeatedly) into &lt;strong&gt;test&lt;/strong&gt; and &lt;strong&gt;training&lt;/strong&gt; sets. It uses the training data to fit the model, and checks if the trained model is able to predict the correct results for the test data. Basically, cross-validation helps to detect over-fitting since a model that fits too closely the training data and its specific peculiarities (noise, random fluctuations) will have a bad prediction performance on the test data. However, the basic requirement for this is, that the test data is independent of the training data. CV achieves this by splitting the data randomly into test and training sets. However, randomly splitting spatial data results in the fact that training points are frequently located next to test points. Since points close to each other are more similar compared to points further away, test and training datasets might not be independent. The consequence is that cross-validation would fail to detect over-fitting in the presence of spatial autocorrelation&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(&lt;em&gt;To understand the &lt;a href=&#34;https://stats.stackexchange.com/questions/36145/linear-regression-and-spatial-autocorrelation&#34;&gt;importance of the autocorrelation concept&lt;/a&gt;, you could read the &lt;a href=&#34;http://rspatial.org/analysis/rst/7-spregression.html&#34;&gt;Spatial regression models paragraph&lt;/a&gt; of the Spatial Data Analysis and Modeling with R website and watch this short &lt;a href=&#34;https://www.youtube.com/watch?v=M9ecMxVG6jQ&#34;&gt;video&lt;/a&gt;&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;To assess how well a model performs at making its predictions actually good predictions, 2 CV methods are often presented :&lt;br /&gt;
* (spatial) k-fold cross validation * (spatial) leave-one-out (refs : &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/pdf/10.1111/geb.12161&#34;&gt;K. Le Rest&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://davidrroberts.wordpress.com/2016/03/11/spatial-leave-one-out-sloo-cross-validation/&#34;&gt;D.R. Roberts&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;How to know which one best fits your needs &lt;a href=&#34;https://stats.stackexchange.com/questions/154830/10-fold-cross-validation-vs-leave-one-out-cross-validation&#34;&gt;(k-fold or leave-one-out)&lt;/a&gt; ? The short answer is to use the leave-one-out method when you have a small amount of samples.&lt;/p&gt;
&lt;p&gt;To check if the trained model is able to predict the correct results for the test data, &lt;a href=&#34;http://r-statistics.co/Linear-Regression.html&#34;&gt;calculating the accuracy measures and error rates&lt;/a&gt; allows to find out the prediction accuracy of the model. &lt;a href=&#34;https://www.geos.ed.ac.uk/~gisteac/gis_book_abridged/files/ch14.pdf&#34;&gt;Paper&lt;/a&gt; about spatial predictions errors&lt;/p&gt;
&lt;p&gt;In your analysis, you might try many variants of the same kind of modeling technique, for example, by adding or removing extra independent variables. In this case, you will need to establish a diagnostic of the measure of success of each of the variants investigated. There is no universal technique to compare these. You can grab some ideas to implement in your own work from the &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0304380010000463&#34;&gt;Aertsen et al. 2010 paper&lt;/a&gt; where they describe a multi-criteria decision analysis for model evaluation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assessing-the-uncertainty-on-the-predicted-values&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Assessing the uncertainty on the predicted values&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;r-guidelines&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R guidelines&lt;/h2&gt;
&lt;p&gt;Now that you have a better insight of what spatialization and multiple linear regressions are, it‚Äôs time to get the job done and dive in some coding work with R !&lt;/p&gt;
&lt;div id=&#34;if-you-are-totally-new-to-programming-with-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;If you are totally new to programming with R‚Ä¶&lt;/h3&gt;
&lt;p&gt;Learning and mastering a new programming language might scare you as it seems as a very difficult goal to achieve. However, with the help of the Internet and the R community, you can quickly start to write your first R programs. You can learn through tutorials (like at &lt;a href=&#34;https://www.datacamp.com/courses/free-introduction-to-r&#34;&gt;Datacamp&lt;/a&gt;), blog posts (like the blog aggregator &lt;a href=&#34;https://www.r-bloggers.com/&#34;&gt;R-Bloggers&lt;/a&gt;), package documentation (on &lt;a href=&#34;https://cran.r-project.org/&#34;&gt;CRAN&lt;/a&gt;) and of course help forums like &lt;a href=&#34;https://stackoverflow.com/&#34;&gt;Stackoverflow&lt;/a&gt; which is where I spend a lot of time searching answers to my questions (most of the time already posted by others).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Why R ?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;R is open-source &lt;a href=&#34;https://www.gnu.org/philosophy/shouldbefree.en.html&#34;&gt;(why it is important)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R is gaining more and more popularity. Mastering it can opens you &lt;a href=&#34;https://thenextweb.com/offers/2018/03/28/tech-giants-are-harnessing-r-programming-learn-it-and-get-hired-with-this-complete-training-bundle/&#34;&gt;many job opportunities&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A good starting point to work with multiple regression analysis with R is &lt;a href=&#34;https://feliperego.github.io/blog/2015/03/12/Multiple-Linear-Regression-First-Steps&#34;&gt;this&lt;/a&gt; tutorial by Felipe Rego. On his excellent blog you will also find a detailed &lt;a href=&#34;https://feliperego.github.io/blog/2015/10/23/Interpreting-Model-Output-In-R&#34;&gt;post&lt;/a&gt; about regression model output interpretation.&lt;/p&gt;
&lt;p&gt;(&lt;em&gt;A special version of spatial regression modeling is the Geographically weighted regression which is described in &lt;a href=&#34;https://rpubs.com/chrisbrunsdon/101305&#34;&gt;this&lt;/a&gt; R tutorial written by Pr. Chris Brundson&lt;/em&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-started-with-r-for-spatial-data-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Getting started with R for spatial data analysis&lt;/h3&gt;
&lt;p&gt;In the &lt;a href=&#34;https://geocompr.robinlovelace.net&#34;&gt;Geocomputation with R book&lt;/a&gt; by Robin Lovelace you will get all you need to get started with spatial data manipulation and analysis with R. The book tutorials make a heavy use of these libraries, and especially the new &lt;a href=&#34;https://edzer.github.io/UseR2017/&#34;&gt;sf package&lt;/a&gt; for spatial data analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sf)            # classes and functions for vector data
library(raster)        # classes and functions for raster data
library(spData)        # load geographic data
library(spDataLarge)   # load larger geographic data&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;useful-r-cheatsheets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Useful R cheatsheets&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf&#34;&gt;dplyr&lt;/a&gt; - Data manipulation&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf&#34;&gt;ggplot2&lt;/a&gt; - Data Visualization&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/OverviewCoordinateReferenceSystems.pdf&#34;&gt;Coordiante reference systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;worth-reading-r-spatial-oriented-blog&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Worth reading R spatial oriented blog&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.r-spatial.org/&#34; class=&#34;uri&#34;&gt;https://www.r-spatial.org/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;a-note-about-coordinate-reference-systems-crs-notations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A note about coordinate reference systems (CRS) notations&lt;/h2&gt;
&lt;div id=&#34;geographic-vs-projected-coordinate-reference-system-crs&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Geographic vs projected coordinate reference system (CRS)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Geographic CRS‚Äôs&lt;/strong&gt; identify any location on the Earth‚Äôs surface using two values ‚Äî longitude and latitude&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Projected CRS‚Äôs&lt;/strong&gt; are based on Cartesian coordinates on an implicitly flat surface. They have an origin, x and y axes, and a linear unit of measurement such as meters. All projected CRSs are based on a geographic CRS, and rely on map projections to convert the three-dimensional surface of the Earth into Easting and Northing (x and y) values in a projected CRS.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;notations-systems-of-crss&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Notations systems of CRSs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://earthdatascience.org/courses/earth-analytics/spatial-data-r/understand-epsg-wkt-and-other-crs-definition-file-types/&#34;&gt;EPSG vs.¬†proj4string notations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Thanks to this post and all its references, you should now be able to start building a multiple regression spatial interpolation analysis based on your own data using R. If you need additional references, you could also check out this multiple linear regression &lt;a href=&#34;https://www.statmethods.net/stats/regression.html&#34;&gt;tutorial&lt;/a&gt; by R.I. Kabacoff.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Quickly publish your R interactive data visualization tools with github pages</title>
      <link>/post/r_interactive_datavis_with_github_pages/</link>
      <pubDate>Wed, 14 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/r_interactive_datavis_with_github_pages/</guid>
      <description>&lt;p&gt;As a data scientist, you certainly produce a bunch of tables, plots, maps and many other kind of outputs to let your data ‚Äúspeak for itself‚Äù. This is your core business and I‚Äôm sure you do it pretty well ! But when it comes to make this data available to your target audience things can quickly get more frustrating. How to share these outputs in a format that everyone can open ? How to easily send these to 100 persons ? How to notify them of any updated output ? How to make these outputs more interactive so that your audience can get a full insight of your data analysis ?&lt;/p&gt;
&lt;p&gt;R and web technologies can help you to solve these problems you probably have already encountered.&lt;/p&gt;
&lt;p&gt;Thanks to the advances in web technologies and the development of powerful Javascript librairies, our web-browsers are now able to render impressive data visualization apps and presentations. These last years, the R community has developed countless libraries (leaflet, shiny, plotly, knitr, etc) that take advantages from these advances.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;You can now easily and quickly transform your analysis outputs in eye catching web apps that make your data intelligible !&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this post we will see how to combine these R libraries capabilities with &lt;a href=&#34;https://pages.github.com/&#34;&gt;Github pages&lt;/a&gt; in order to quickly make your top notch data visualization output available to your audience (and don‚Äôt be modest : to the world)&lt;/p&gt;
&lt;p&gt;Before we dig into the topic, it is important to first understand what a webpage actually is. So here is a short recap !&lt;/p&gt;
&lt;div id=&#34;how-does-a-webpage-works-in-simple-terms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How does a webpage works (in simple terms) ?&lt;/h2&gt;
&lt;p&gt;When you enter an address (URL) in your web-browser, it sends a request to the hosting server. In returns, the server sends to your web-browser the requested content in the form of an HTML file. HTML is simply a kind of formatted text that contains specific tags to structure your text (headings, tables, lists, text formatting, etc) and that can eventually link to other documents. The role of your web-browser is to translate this non-human readable HTML to its human friendly version (if it is not clear, check &lt;a href=&#34;https://www.w3schools.com/html/tryit.asp?filename=tryhtml_default&#34;&gt;this&lt;/a&gt; example).&lt;/p&gt;
&lt;p&gt;This HTML can be ‚Äúupgraded‚Äù by 2 other languages also supported by your web-broser : CSS and Javascript. While CSS is responsible for the styling (font color, background color, font-size, etc), the Javascript manages the interactivity (like zooming on a map), the animations and the actions that can be performed by/on the web-page (like actions triggered by clicking on a button). And that‚Äôs it ! You can build any webpage with these 3 ingredients.&lt;/p&gt;
&lt;p&gt;As Github pages only works with static content, an important thing to get in mind is the &lt;a href=&#34;http://smallbusiness.chron.com/difference-between-dynamic-static-pages-69951.html&#34;&gt;difference&lt;/a&gt; between a static and a dynamic webpage !&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-github-pages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is Github pages&lt;/h2&gt;
&lt;p&gt;For those who are familiar with the version control software git you most probably already knows &lt;a href=&#34;https://github.com/&#34;&gt;Github&lt;/a&gt; as a git repository hosting service (if you don‚Äôt know what &lt;a href=&#34;https://git-scm.com/&#34;&gt;git&lt;/a&gt; is, you really &lt;strong&gt;must&lt;/strong&gt; get to &lt;a href=&#34;http://r-bio.github.io/intro-git-rstudio/&#34;&gt;know it&lt;/a&gt; to impressively speed up your (R) code development). Github offers many other possibilities : collaborative code developement, issues tracking and discussions, project presentation page, wiki, &lt;a href=&#34;https://jekyllrb.com/&#34;&gt;Jekyll blog&lt;/a&gt; and various integrations with other web services thanks to their API. Among these features, exists &lt;a href=&#34;https://pages.github.com/&#34;&gt;Github pages&lt;/a&gt; which is intended to allow you to publish &lt;strong&gt;static&lt;/strong&gt; pages without the need to run our rent your own webserver. &lt;strong&gt;So, as long as your datavisualization output does not require any running backend (be it in node.js, Python, R, Java, Ruby, etc), you can host it on Github pages !&lt;/strong&gt; Unfortunately this means that &lt;a href=&#34;https://shiny.rstudio.com/&#34;&gt;R Shiny apps&lt;/a&gt; can not be hosted on Github pages. But yeah, you can still publish &lt;a href=&#34;https://rstudio.github.io/leaflet/&#34;&gt;leaflet&lt;/a&gt; maps, &lt;a href=&#34;https://plot.ly/r/&#34;&gt;plotly&lt;/a&gt; graphs and &lt;a href=&#34;https://yihui.name/knitr/demo/minimal/&#34;&gt;knitr&lt;/a&gt; html reports ! That already opens up a wide range of possibilities !&lt;/p&gt;
&lt;p&gt;What does Github pages actually does ?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Github pages turns your repository containing your source file hosted at :&lt;br /&gt;
&lt;code&gt;https://github.com/yourUserName/repositoryName&lt;/code&gt;&lt;br /&gt;
to a rendered web-page hosted at :&lt;br /&gt;
&lt;code&gt;https://yourUserName.github.com/repositoryName&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-publish-your-r-outputs-to-github-pages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How to publish your R outputs to Github pages ?&lt;/h2&gt;
&lt;p&gt;The workflow is as follows (more details with an example here below) :&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Exports your R analysis outputs to a specific folder&lt;/li&gt;
&lt;li&gt;Make this folder a git repository&lt;/li&gt;
&lt;li&gt;Create a &lt;code&gt;gh-pages&lt;/code&gt; branch&lt;/li&gt;
&lt;li&gt;Commit your changes&lt;/li&gt;
&lt;li&gt;Push to Github&lt;/li&gt;
&lt;li&gt;Visit your published work at &lt;code&gt;https://yourGithubUsername.github.io/repositoryname&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To illustrate this process, we will use R to build an interactive leaflet map that displays two layers : A DEM of Belgium and a &lt;a href=&#34;https://en.wikipedia.org/wiki/Web_Map_Service&#34;&gt;WMS&lt;/a&gt; layer of currently observed precipitations provided by the &lt;a href=&#34;http://www.knmi.nl/home&#34;&gt;KNMI&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;first-things-first-create-an-online-repository-at-github&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;First things first : create an online repository at Github&lt;/h3&gt;
&lt;p&gt;Once you have created a Github account, go to &lt;code&gt;https://github.com/yourUserName&lt;/code&gt;, click on the &lt;em&gt;+&lt;/em&gt; button and select &lt;em&gt;new repository&lt;/em&gt;. Give it the name &lt;code&gt;myoutputs&lt;/code&gt; (or whatever you want) :&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./post/R_interactive_datavis_with_github_pages_files/new_repository.png&#34; alt=&#34;github new repository screenshot&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;github new repository screenshot&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Eventually add a description and choose an existing .gitignore file and license and click on &lt;em&gt;create repository&lt;/em&gt;. You are now on your Github &lt;em&gt;myoutputs&lt;/em&gt; repository page. Click on the green button &lt;em&gt;Clone or download&lt;/em&gt;, then on the link &lt;em&gt;use HTTPS&lt;/em&gt; (you can of course also use &lt;a href=&#34;https://help.github.com/articles/connecting-to-github-with-ssh/&#34;&gt;SSH&lt;/a&gt; if you know what it means) and copy the link provided in the text box :&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./post/R_interactive_datavis_with_github_pages_files/clone_repo.png&#34; alt=&#34;github clone screenshot&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;github clone screenshot&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;sync-i.e.clone-this-repository-to-your-computer-and-create-the-gh-pages-branch-for-auto-publishing-to-github-pages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sync (i.e.¬†clone) this repository to your computer and create the gh-pages branch for auto-publishing to Github pages&lt;/h3&gt;
&lt;p&gt;Let‚Äôs create a folder called &lt;code&gt;dev&lt;/code&gt; under your home directory into which we will clone the online repository by pasting its addresse as a parameter of the &lt;code&gt;git clone&lt;/code&gt; command in your terminal (&lt;a href=&#34;http://dont-be-afraid-to-commit.readthedocs.io/en/latest/git/commandlinegit.html&#34;&gt;more about the use of git with the command line&lt;/a&gt;) :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ mdkir ~/dev
$ cd ~/dev
$ git clone https://github.com/yourUserName/myoutputs.git&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Enter your Github username and password (if you have choosen HTTPS instead of SSH), press enter and your &lt;code&gt;dev&lt;/code&gt; folder now contains a &lt;code&gt;myoutputs&lt;/code&gt; folder which is a git repository (i.e.¬†the root of the &lt;code&gt;myoutputs&lt;/code&gt; folder contains a hidden &lt;code&gt;.git&lt;/code&gt; folder that manages all its git features). Let‚Äôs check this :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ ls -al&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If everything went OK, you should see the &lt;code&gt;myoutputs&lt;/code&gt; and the &lt;code&gt;.git&lt;/code&gt; folder listed in your terminal. Now, let‚Äôs create a specific branch (more about branches &lt;a href=&#34;https://git-scm.com/book/en/v2/Git-Branching-Branches-in-a-Nutshell&#34;&gt;here&lt;/a&gt;) for automatic hosting and publishing of your outputs! Github uses &lt;code&gt;gh-pages&lt;/code&gt; as the default branch name to create an hosted webpage version of your repository source code. So let‚Äôs create it and use it !&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ git checkout -b gh-pages&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;code-your-interactive-leaflet-map-with-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Code your interactive leaflet map with R !&lt;/h3&gt;
&lt;p&gt;Your are now ready to build some git versioned code and make it ready to be published on the web through the magic of git and Github pages !&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://pokyah.github.io/pokyah-maps/bel-dem-knmi/demo-map.R&#34;&gt;Download&lt;/a&gt; the source of the &lt;code&gt;demo-map.R&lt;/code&gt; (which is intended to produce an HTML leaflet map) script and save it under your &lt;code&gt;myoutputs&lt;/code&gt;. Open your terminal inside this folder and execute it :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ Rscript demo-map.R&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The script has produced a &lt;code&gt;demo-map.html&lt;/code&gt; file containing the interactive map plus a &lt;code&gt;demo-map_files&lt;/code&gt; folder containing all the required javascript libraries required to make it interactive. It has also saved 3 files resulting from the download of the raster elevation data. The resulting map looks like this :&lt;/p&gt;
&lt;iframe src=&#34;https://pokyah.github.io/pokyah-maps/bel-dem-knmi/&#34; width=&#34;100%&#34; height=&#34;400&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;If you get errors it might be because you don‚Äôt have the required libraries installed. To avoid such problems, simply install the missing libraries (and if you are adventurous enough, you can have a look at my &lt;a href=&#34;it%20%7B%7B%20site.baseurl%20%7D%7D%7B%%20post_url%202018-03-01-using-r-with-docker%20%%7D&#34;&gt;R + Docker tutorial&lt;/a&gt;!)&lt;/p&gt;
&lt;p&gt;Your interactive web map is now built ! You can locally open it by right-clicking on the &lt;code&gt;demo-map.html&lt;/code&gt; file and choose to open it with your favorite web-browser. Check the various buttons to be sure that everything works as expected. What is important to know is that this impressive web app does not need any backend to run. Once the page is loaded, everything works inside your web-browser thanks to HTML, CSS and Javascript !&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ok, but how is it then possible for me navigate and zoom in every part of the world without having to run a server to get the base layer tiles ?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That‚Äôs probably what you will tell ! The trick is that leaflet render tiles stored on a third party tiles provider (i.e.¬†a web-server). It is actually a simple line of Javascript that does the magic of calling the tiles and serving these to your web-browser. If you turn your wifi off, you will see that you won‚Äôt be able anymore to see the base layer while navigating the world.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;publish-it-online-using-gh-pages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Publish it online using gh-pages !&lt;/h3&gt;
&lt;p&gt;Head back to your terminal (opened in your &lt;code&gt;myoutputs&lt;/code&gt; folder) and save and publish your work to Github.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ git add .
$ git commit -m &amp;quot;adding interactive demo-map.html&amp;quot;
$ git push --set-upstream origin gh-pages&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the source code of your interactive map (both the &lt;code&gt;demo-map.R&lt;/code&gt; and the &lt;code&gt;demo-map.html&lt;/code&gt; ) has been pushed to &lt;code&gt;https://github.com/yourUserName/myoutputs&lt;/code&gt; and your hosted interactive map is rendered at &lt;code&gt;https://yourUserName.github.io/myoutputs/demo-map.html&lt;/code&gt; !&lt;/p&gt;
&lt;p&gt;Great ! Simply share this link to your audience and you are done ! Your interactive webmap is available to them !&lt;/p&gt;
&lt;p&gt;Sometimes github pages struggles to rebuild your rendered page when you commit your changes. If this happens, you can force github pages to rebuild it using these two git instructions (solution found on &lt;a href=&#34;https://stackoverflow.com/questions/24098792/how-to-force-github-pages-build&#34;&gt;stackoverflow&lt;/a&gt;) :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ git commit -m &amp;#39;rebuild pages&amp;#39; --allow-empty
$ git push origin gh-pages&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;some-optionally-tricks-to-improve-this-workflow&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Some optionally tricks to improve this workflow&lt;/h2&gt;
&lt;p&gt;If you want to showcase multiple interactive data visualizations outputs, it might be cool to have a webpage that presents all of them so that your visitors can easily discover your work. The simplest solution is to create an &lt;code&gt;index.html&lt;/code&gt; file that lists all your outputs and that is located at the root of your &lt;code&gt;myoutputs&lt;/code&gt; directory. Doing so, while your visitors head at &lt;code&gt;https://yourUserName.github.io/myoutputs&lt;/code&gt;, the &lt;code&gt;index.html&lt;/code&gt; will act as a home page and your visitors will receive a listing of the outputs you have add to your &lt;code&gt;myoutputs&lt;/code&gt; repository.&lt;/p&gt;
&lt;p&gt;You have two options to maintain this directory listing &lt;code&gt;index.html&lt;/code&gt; file updated. Either you manually add a new line for each new interactive output you want to showcase, either you run a bash script that build the &lt;code&gt;index.html&lt;/code&gt; file for you (preferred).&lt;/p&gt;
&lt;div id=&#34;bash-script-to-build-the-directory-listing-index.html-file&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;bash script to build the directory listing index.html file&lt;/h3&gt;
&lt;p&gt;Download and save &lt;a href=&#34;https://pokyah.github.io/pokyah-maps/index-html.sh&#34;&gt;this&lt;/a&gt; bash script under your &lt;code&gt;myoutputs&lt;/code&gt; folder. Make it executable :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ chmod a+x index-html.sh&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This script is intendend to automatically generate an index.html files that lists all the files available in a specific folder. Let‚Äôs run it :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ ls | ./index-html.sh &amp;gt; index.html&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You now have a nice index.html files that lists all your files stored in your &lt;code&gt;myoutputs&lt;/code&gt; folder.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pushing-the-index.html-file-to-github&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;pushing the index.html file to github&lt;/h3&gt;
&lt;p&gt;Each time, you run this bash script to update you index.html file, you of course have to push it to Github so that when your visitors head at &lt;code&gt;https://yourUserName.github.io/myoutputs&lt;/code&gt; they get an updated list of all your files available. For this purpose we do as previsously mentioned : add, commit and push :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ git add .
$ git commit -m &amp;quot;adding index.html and updating it with bash script&amp;quot;
$ git push origin gh-pages&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;You are now able to publicly share your best R interactive datavisulization HTML outputs thanks to Github pages. You are of course not limited to R. You can use this system to showcase any HTML/CSS/JS creation, be it a full static website (great templates available &lt;a href=&#34;https://html5up.net/&#34;&gt;here&lt;/a&gt;) our a little javascript game for example.&lt;br /&gt;
If you want to easily host a blog with Github pages, have a look at Jekyll and &lt;a href=&#34;https://github.com/barryclark/jekyll-now&#34;&gt;this excellent&lt;/a&gt; easy and instant Jekyll install repository (that I have used to build this blog).&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using R with Docker</title>
      <link>/post/using-r-with-docker/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/using-r-with-docker/</guid>
      <description>&lt;p&gt;Why should you do that ? There are two main reasons to use R in conjunction with Docker. First, it allows you to quickly and easily share your work wathever the OS and R configuration of your collaborators. Hassle free collaboration ! Second, it allows you to work in an isolated environment. This means that you will never pollute your OS and e.g.¬†run in time-consuming re-installation procedures due to broken configuration. In case of OS crash, simply relaunch your &lt;em&gt;Docker R container&lt;/em&gt; with a single command (more about containers below) and you are ready to work !&lt;/p&gt;
&lt;p&gt;This tutorial is an introduction to R with Docker. It it not an extensive description of the &lt;a href=&#34;https://docs.docker.com/&#34;&gt;enormous amount of features&lt;/a&gt; and all the complexity of Docker. It‚Äôs rather a good base to get started that I‚Äôve written based on my own R development needs.&lt;/p&gt;
&lt;div id=&#34;what-is-a-docker-container&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is a Docker container ?&lt;/h2&gt;
&lt;p&gt;Docker is the piece of software that allows you to run &lt;strong&gt;containers&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;From the &lt;a href=&#34;https://www.docker.com/what-container&#34;&gt;official Docker website&lt;/a&gt; :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A container image is a lightweight, stand-alone, executable package of a piece of software that includes everything needed to run it: code, runtime, system tools, system libraries, settings. Available for both Linux and Windows based apps, containerized software will always run the same, regardless of the environment. Containers isolate software from its surroundings, for example differences between development and staging environments and help reduce conflicts between teams running different software on the same infrastructure.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This container approach has many advantages compares to the use of virtual machines : lightweight, quick and modular.&lt;/p&gt;
&lt;p&gt;In the Docker terminology, a containers actually means a running instance of an &lt;strong&gt;image&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Again, from the official Docker Website :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Docker images are the basis of containers. An Image is an ordered collection of root filesystem changes and the corresponding execution parameters for use within a container runtime. An image typically contains a union of layered filesystems stacked on top of each other. An image does not have state and it never changes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;how-docker-will-help-you-with-your-r-related-work&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How Docker will help you with your R related work ?&lt;/h2&gt;
&lt;p&gt;Now that you understand what a container is, I‚Äôll tell you what you can do with Docker in the context of you R work.&lt;/p&gt;
&lt;p&gt;You can create and use a container that runs with the Linux distro &lt;em&gt;of your choice&lt;/em&gt;, with a version of R &lt;em&gt;of your choice&lt;/em&gt;, the packages and required OS dependencies &lt;em&gt;of your choices&lt;/em&gt;, and all of this in a totally isolated environment that is setup in seconds. And of course, you can create multiple containers with various R configurations depending of your needs !&lt;/p&gt;
&lt;p&gt;This means that you will never run anymore in compatibility problems. It will also make your work &lt;a href=&#34;https://www.nature.com/articles/s41562-016-0021&#34;&gt;reproductible&lt;/a&gt; as you can share your containers with colleagues.&lt;/p&gt;
&lt;p&gt;Docker also makes the use of the &lt;a href=&#34;https://rstudio.github.io/packrat/&#34;&gt;Packrat&lt;/a&gt; dependency management quite obsolete.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;docker-installation-instructions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Docker installation instructions&lt;/h2&gt;
&lt;p&gt;You know why you should use Docker in the context of your R work and you want to install it now ! Well, to do it, simply follow the &lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-docker-ce-1&#34;&gt;installation instructions&lt;/a&gt; on the Docker official website or follow this nice &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-16-04&#34;&gt;Digital Ocean tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Before we dive into the R part, you will need to understand some essential Docker concepts.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;essential-docker-concepts-commands&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Essential Docker concepts &amp;amp; commands&lt;/h2&gt;
&lt;p&gt;Each &lt;strong&gt;image&lt;/strong&gt; has its own &lt;strong&gt;name&lt;/strong&gt; and &lt;strong&gt;ID&lt;/strong&gt;. You can list all your available Docker images and get their name and ID using the &lt;code&gt;image&lt;/code&gt; command :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
agrometeor          latest              fea4eeec5c2a        10 days ago         2.41GB&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To &lt;strong&gt;run an image as a container&lt;/strong&gt;, simply use the &lt;code&gt;run&lt;/code&gt; command with the image ID or name :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ docker run &amp;lt;IMAGE-NAME&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that this command can receive many optional parameters (we will see an example later).&lt;/p&gt;
&lt;p&gt;You can also run a container from an image which is hosted on &lt;a href=&#34;https://hub.docker.com/r/pokyah/agrometeordocker/&#34;&gt;Docker Hub&lt;/a&gt;. Docker will automatically download it on your computer and run it as a container once it is downloaded (to use this feature, you will first need to create a Docker hub account).&lt;/p&gt;
&lt;p&gt;For geospatial R work you could for example run the image named &lt;a href=&#34;https://hub.docker.com/r/rocker/geospatial/&#34;&gt;rocker/geospatial&lt;/a&gt; which contains Linux, R, Rstudio and the most famous R spatial packages and their OS dependencies :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ docker run rocker/geospatial&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can of course run multiple different images simultanesously but you can also run a single image simultaneously in multiple separate containers. To &lt;strong&gt;list all your running Docker containers&lt;/strong&gt; and get their name and ID, use the &lt;code&gt;ps&lt;/code&gt; command. Note that the name is randomly generated by Docker.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                    NAMES
b18f77625a00        agrometeor          &amp;quot;/init&amp;quot;             About an hour ago   Up About an hour    0.0.0.0:8787-&amp;gt;8787/tcp   silly_roentgen
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running containers use computing ressources. To &lt;strong&gt;stop and remove&lt;/strong&gt; a running container use the &lt;code&gt;rm&lt;/code&gt; command :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ docker rm -f &amp;lt;CONTAINER-ID&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pay attention that when you stop a container, all the work that has been done inside the container is lost ! This is on purpose and we will later see the proper and efficient way to save your R developments made inside a container. If you want to save modifications made inside a container (e.g.¬†adding a R library and its OS dependencies) you have to &lt;code&gt;commit&lt;/code&gt; your container. But this is out of the scope of this tutorial. If you are interested, you can read the corresponding &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/commit/#commit-a-container-with-new-configurations&#34;&gt;doc&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you need it, you can explore the file system of the running container (similarly to what you do when you are connected to a server using ssh conection) :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ docker exec -t -i &amp;lt;CONTAINER-ID&amp;gt; /bin/bash&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Docker is not limited to images existing on Docker Hub. It allows you to create your images with the configuration of your own. Creativity is the limit. Creating a Docker image requires a &lt;strong&gt;Dockfile&lt;/strong&gt; which is simply a configuration file that tells Docker what to put in your image. For example, you can find the Dockfile that was used to create the rocker/geospatial image that we mentioned earlier on &lt;a href=&#34;https://github.com/rocker-org/geospatial/blob/master/Dockerfile&#34;&gt;github&lt;/a&gt; . To &lt;strong&gt;build an image&lt;/strong&gt; from a dockfile you simply open a terminal in the folder containing the dockfile and execute the &lt;code&gt;build&lt;/code&gt; command with the name you want to attribute to your image (don‚Äôt forget the ‚Äú.‚Äù at the end !) :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ docker build -t &amp;lt;IMAGE-NAME&amp;gt; .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There a lot of ressources on the web that explain how to create your own images. Check my selection in the further reading section at the end of the post.&lt;/p&gt;
&lt;p&gt;In case you are sure you will not anymore run an image as container(s), you can delete it to save some space on your computer :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ docker rmi &amp;lt;IMAGE_NAME:VERSION/IMAGE-ID&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And to delete all images (really ?!) :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ docker rmi $(docker images -qf &amp;quot;dangling=true&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;using-rstudio-inside-a-docker-container-and-saving-your-work&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using RStudio inside a Docker container and saving your work&lt;/h2&gt;
&lt;p&gt;Let‚Äôs dive in the latest part of this tutorial : running R inside a container. It‚Äôs actually pretty simple. It involves 2 steps :&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Choosing the pre-build R oriented Docker image you want to use&lt;/li&gt;
&lt;li&gt;Running it as a container with optional parameters&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let‚Äôs say you need to make some R developments made easier with the &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidyverse&lt;/a&gt; family packages. To do this you will download the pre-built &lt;a href=&#34;https://hub.docker.com/r/rocker/tidyverse/image&#34;&gt;rocker/tidyverse&lt;/a&gt; from Docker hub using the command &lt;code&gt;pull&lt;/code&gt; (note the similarity with &lt;a href=&#34;http://r-bio.github.io/intro-git-rstudio/&#34;&gt;git&lt;/a&gt;):&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ docker pull rocker/tidyverse&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remember that we have learned that once closed, containers loose all the modifications you have made within it. So, &lt;strong&gt;how to save your R developments made within a container&lt;/strong&gt; ? The trick is to actually &lt;strong&gt;mount your project folder from your host computer to the container&lt;/strong&gt;. This is achieved by passing optional parameters to the &lt;code&gt;run&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;If you want to run a container from the rocker/tidyverse image with an R project located in your host computer at &lt;code&gt;/home/yourUsername/Rprojects/yourProject/&lt;/code&gt; and work in RStudio, use the &lt;code&gt;run&lt;/code&gt; command with these optional parameters :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;$ docker run -w /home/rstudio/ rm -p 8787:8787 -v /yourUsername/Rprojects/yourProject/:/home/rstudio/ rocker/tidyverse&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Docker will instantiate a new container from the rocker/tidyverse image and make your project folder available to the container by mounting it. All the modifications that you made to your mounted host folder from your container will be effective in your host machine. So once you stop your container, don‚Äôt worry, your modifications will be saved !&lt;/p&gt;
&lt;p&gt;To launch your container RStudio install, open a web-browser and navigate to &lt;code&gt;http://localhost:8787&lt;/code&gt;. You habitual RStudio interface will be launched within a few seconds and your mounted folder will appear in the files pane. &lt;strong&gt;Congratulations, you are now ready to work within a dockerized RStudio install !&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In most of the cases, before running an image, you will need to customise it so that it reflects your own needs. &lt;strong&gt;Customising an image&lt;/strong&gt; requires to &lt;strong&gt;edit its Dockerfile&lt;/strong&gt; and rebuild the image as mentioned earlier.&lt;/p&gt;
&lt;p&gt;To keep &lt;strong&gt;git versioned Dockerfile -s&lt;/strong&gt; of your images, you can push them to &lt;a href=&#34;https://github.com/&#34;&gt;Github&lt;/a&gt;. Hosting your Dockerfile on Github offers you a nice feature : &lt;a href=&#34;https://docs.docker.com/docker-hub/builds/&#34;&gt;automated builds&lt;/a&gt;. Once enabled, each time you push a modification of your Dockerfile to Github, Docker will rebuild your image and make it ready to be pulled by others.&lt;/p&gt;
&lt;p&gt;You can share this very specific R environment with your co-workers. First, share them this tutorial and then share your image. For this purpose, you have two solutions :&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Sending them the corresponding Dockerfile and let them build the image on their machine (more complex)&lt;/li&gt;
&lt;li&gt;Upload your image to Docker hub (manually or with the automated build feature) and simply send them the name of your image so that then can you it immediately use it with the &lt;code&gt;run&lt;/code&gt; command&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;You have learned how to use Docker to run your own customized R isolated environment inside a container and how to share this specific environment with your colleagues.&lt;/p&gt;
&lt;p&gt;If you want to try a my pokyah/agrometeor container, have a look at its &lt;a href=&#34;https://github.com/pokyah/agrometeorDocker&#34;&gt;repository&lt;/a&gt;. There you will also learn how to create a custom bash command to launch your containers.&lt;/p&gt;
&lt;p&gt;In a next tutorial, I‚Äôll explain you how to run a container able to connect to an external postgreSQL database.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;future-readings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Future readings&lt;/h2&gt;
&lt;div id=&#34;good-tutorials&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Good tutorials&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.andrewheiss.com/blog/2017/04/27/super-basic-practical-guide-to-docker-and-rstudio/&#34;&gt;Andrew Heiss tuto&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dirk.eddelbuettel.com/papers/useR2015_docker.pdf&#34;&gt;Dirk Eddelbuettel presentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://knausb.github.io/2017/06/running-r-in-docker/&#34;&gt;Brian J. Knaus CLI tuto&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.r-bloggers.com/r-3-3-0-is-another-motivation-for-docker/&#34;&gt;R-Blogger post&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;dockerfile-customization&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Dockerfile customization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://o2r.info/2017/05/30/containerit-package/&#34;&gt;R package to create Dockerfile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://ropenscilabs.github.io/r-docker-tutorial/05-dockerfiles.html&#34;&gt;tutorial from ropenscilabs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.mirantis.com/blog/how-do-i-create-a-new-docker-image-for-my-application/&#34;&gt;mirantis blog tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/45289764/install-r-packages-using-docker-file&#34;&gt;stackoverflow install-r-packages-using-docker-file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/46902203/verify-r-packages-installed-into-docker-container&#34;&gt;stackoverflow verify-r-packages-installed-into-docker-container&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/26500174/upload-local-files-to-docker-container?noredirect=1&amp;amp;lq=1&#34;&gt;stackoverflow upload-local-files-to-docker-container&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Assessing the agreement level between two quantitative methods of measurements : understanding the Bland Altman analysis</title>
      <link>/post/assessing-the-agreement-between-two-quantitative-methods-of-measurements-understanding-the-bland-altman-analysis/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/assessing-the-agreement-between-two-quantitative-methods-of-measurements-understanding-the-bland-altman-analysis/</guid>
      <description>&lt;p&gt;Attempting to statistically assess the agreement level between two quantitative methods of measurements requires a validation tool.&lt;/p&gt;
&lt;p&gt;A widely adopted tool is the correlation study computed with one method as predictor and the other as response variable (e.g.¬†see &lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1002/wea.2158/pdf&#34;&gt;this&lt;/a&gt; publication that compares temperature measurements obtained by two different kind of weather stations at the exact same location).&lt;/p&gt;
&lt;p&gt;However, as described by &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4470095/&#34;&gt;Giavarina (2015)&lt;/a&gt;, correlation study should not be used to asses the comparatibility or agreement between two instruments (because it studies the relation between one variable and the other and not the &lt;strong&gt;differences&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;In 1986, &lt;a href=&#34;https://www-users.york.ac.uk/~mb55/meas/ba.pdf&#34;&gt;Bland and Altman&lt;/a&gt; have proposed an analysis that quantifies the agreement between two quantitative sets of measurements of the same parameter by statistically studying the behaviors of the differences between paired measurements. This analysis is useful to determine if a method can be used interoperably with another without the need of a correction model&lt;/p&gt;
&lt;div id=&#34;some-words-about-measurements-difference&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Some words about measurements difference&lt;/h2&gt;
&lt;p&gt;From &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4470095/&#34;&gt;Giavarina (2015)&lt;/a&gt; :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An ideal model would claim that the measurements obtained by one method or another gave exactly the same results. So, all the differences would be equal to zero. But any measurement of variables always implies some degree of error. Even the mere analytical imprecision for method A and method B generates a variability of the differences. However, if the variability of the differences were only linked to analytical imprecision of each of the two methods, the average of these differences should be zero. This is the first point required to evaluate the agreement between the two methods: look at the average of the differences between the paired data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;quick-presentation-of-the-bland-altman-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quick presentation of the Bland Altman analysis&lt;/h2&gt;
&lt;p&gt;Their graphical method plots the &lt;strong&gt;differences between the two paired measurements&lt;/strong&gt; against &lt;strong&gt;the averages of these measurements&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Here is an examplative Bland-Altman plot : [blandAltman plot example]({{ ‚Äú/assets/images/blandAltman.png‚Äù | absolute_url }})&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/BlandAltmanLeh/vignettes/Intro.html&#34;&gt;Source&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Horizontal lines are drawn at the &lt;strong&gt;mean difference&lt;/strong&gt; (thick red line), and at the upper and lower &lt;strong&gt;limits of agreement&lt;/strong&gt; (thick blue lines) together with their 0.95 &lt;a href=&#34;https://www.mathsisfun.com/data/confidence-interval.html&#34;&gt;confidence interval - CI&lt;/a&gt; (thin lines).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;strong&gt;mean difference&lt;/strong&gt; is the estimated &lt;strong&gt;bias&lt;/strong&gt;. Its 0.95 CI illustrates the magnitude of the systematic difference.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;strong&gt;limits of agreement&lt;/strong&gt; measure the &lt;strong&gt;random fluctuations around the mean difference&lt;/strong&gt;. These correspond to the mean difference plus and minus 1.96 times the standard deviation of the differences. These lines tell us how far apart measurements by 2 methods were more likely to be for most individuals.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The Maximum allowed difference between methods (D)&lt;/strong&gt; is an arbitrary treshold which value must be chosen so that differences in the range ‚àíD to D are considered irrelevant or neglectable in the context of your study.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;interpretation-guidelines&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Interpretation guidelines&lt;/h2&gt;
&lt;p&gt;The plot allows to infer some information about the agreement of two methods :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If the line of equality (horizontal line at 0) is not in the mean difference 0.95 CI, there is a &lt;strong&gt;significant systematic difference&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If the mean value of the difference differs significantly from 0, this indicates the presence of a &lt;strong&gt;fixed bias&lt;/strong&gt;. This bias can be adjusted for by subtracting the mean difference from the the measurements of the method we want to determine if it can substituate the other.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If the limits of agreement do not exceed the maximum allowed difference, the two methods are considered to be &lt;strong&gt;in agreement&lt;/strong&gt;. They are therefore considered as interchangeable. This interpretation does not however takes CI into accounts (see next point).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If the maximum allowed difference is higher than the 0.95 upper limit of the higher limit of agreement and if the maximum allowed difference is lower than the 0.95 lower limit of the lower limit, we are &lt;strong&gt;95% certain that the methods do not disagree&lt;/strong&gt; (if the differences are &lt;a href=&#34;https://rexplorations.wordpress.com/2015/08/11/normality-tests-in-r/&#34;&gt;normally distributed&lt;/a&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If the scatter presents a trend, there is a relationship between the differences and the magnitude of measurements (&lt;strong&gt;proportional error/bias&lt;/strong&gt;). The existence of such a proportional bias indicates that the methods do not agree equally through the range of measurements. To formally evaluate this relationship, one could compute a regression model between the difference and the average of the 2 methods.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;some-usage-precautions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Some usage precautions&lt;/h2&gt;
&lt;p&gt;The Bland and Altman analysis allows to determine if the bias is significant (e.i. the line of equality is not within the confidence interval of the mean difference) &lt;strong&gt;but&lt;/strong&gt; it does not allow to say if the agreement is sufficient or suitable for your instruments interoperability.&lt;/p&gt;
&lt;p&gt;This analysis modestly quantifies the bias and a range of agreement within which 95% of the differences between one measurement and the other are included.&lt;/p&gt;
&lt;p&gt;Only the &lt;strong&gt;context of your analysis&lt;/strong&gt; could define whether the agreement interval is too wide or sufficiently narrow for your purpose. This is why you should arbitrary set the limits of maximum acceptable differences (limits of agreement expected) based on relevant criteria defined in the context of your analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;software-implementation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Software implementation&lt;/h2&gt;
&lt;p&gt;I mainly work in R (&lt;a href=&#34;https://www.r-bloggers.com/why-use-r-five-reasons/&#34;&gt;and you should too&lt;/a&gt;). If you already do so, I would recommand you the excellent &lt;a href=&#34;https://cran.r-project.org/web/packages/BlandAltmanLeh/vignettes/Intro.html&#34;&gt;BlandAltmanLeh&lt;/a&gt; package that is sufficiently well document in order to perform your own Bland Altman analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;see-also&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;See also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.medcalc.org/manual/blandaltman.php&#34;&gt;medcalc.org Bland Altman explanation page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Bland%E2%80%93Altman_plot#/media/File:Bland-Alman_Plot_with_CI%27s_on_LOA.png&#34;&gt;Bland Altman Wikipedia page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://repository.uwl.ac.uk/id/eprint/2044/1/Amoako-Attah-Jahromi-2015-Method-comparison-analysis-of-dwellings-temperatures-in-the-UK.pdf&#34;&gt;a scientific paper that presents a use case of Bland Altman study in the context of temperature measurement&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Presentation of the Agromet Project</title>
      <link>/post/presentation-of-agromet-project/</link>
      <pubDate>Tue, 30 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/presentation-of-agromet-project/</guid>
      <description>&lt;div id=&#34;the-agromet-project&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The AGROMET Project&lt;/h1&gt;
&lt;p&gt;Construction of an operational web-platform designed for real-time agro-meteorological data dissemination at high spatial (1km¬≤) and temporal (hourly) resolution.&lt;/p&gt;
&lt;div id=&#34;context&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Context&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.eppo.int/PPPRODUCTS/information/2009_0128_EU-e.pdf&#34;&gt;European directive 2009/128/CE&lt;/a&gt; imposes member-states to set up tools that allow for a more rational use of crop protection products. Among these tools, agricultural warning systems, based on crop monitoring models for the control of pests and diseases are widely adopted and have proved their efficiency. However, due to the difficulty to get meteorological data at high spatial resolution (at the parcel scale), they still are underused. The use of supervised machine learning algorithms (Kriging, Multiple Regressions, Artificial Neural Networks, etc.) makes it possible to interpolate data provided by physical weather stations in such a way that a high spatial resolution network (mesh size of 1 km2) of virtual weather stations could be generated. This is the main objective of the AGROMET project.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;objectives&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Objectives&lt;/h2&gt;
&lt;p&gt;The project aims to set up an operational web-platform designed for real-time agro-meteorological data dissemination at high spatial (1km2) and temporal (hourly) resolution. To achieve the availability of data at such a high spatial resolution, we plan to ‚Äúspatialize‚Äù the real-time data sent by more than 30 connected physical weather stations belonging to the PAMESEB and RMI networks. This spatialization will then result in a gridded dataset corresponding to a network of 16 000 virtual stations uniformly spread on the whole territory of Wallonia. These ‚Äúspatialized‚Äù data will be made available through a web-platform providing interactive visualization widgets (maps, charts, tables and various indicators) and an API allowing their use on the fly, notably by agricultural warning systems providers. An extensive and precise documentation about data origin, geo-statistic algorithms used and uncertainty will also be available.&lt;/p&gt;
&lt;p&gt;The following figure shows a first draft of the functional architecture of the platform :&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./post/agromet_presentation_files/agromet_schema.jpg&#34; alt=&#34;agromet schema&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;agromet schema&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;practical-details&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Practical details&lt;/h2&gt;
&lt;p&gt;The agro-meteorological parameters to be spatialized are the following :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;air temperature at 1.5 m above ground,&lt;/li&gt;
&lt;li&gt;relative humidity at 1.5 m above ground,&lt;/li&gt;
&lt;li&gt;leaves wetness,&lt;/li&gt;
&lt;li&gt;rainfall&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Given that the quality of the output data from models used in agricultural warnings is largely dependent on the quality of the input weather data, particular attention will be given to the :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;control and validation of the datasets generated by the weather stations,&lt;/li&gt;
&lt;li&gt;estimation of the uncertainty of the data generated by the network of virtual stations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The choice of the appropriate interpolation methods that will be used to populate the 16 000 virtual weather stations network will rely on investigations already performed in other institutions. Inspired by these experiences and the available scientific literature, tests will be conducted for each of the meteorological variables, in order to determine which will be the most adapted ‚Äúspatialization‚Äù method (e.g.¬†Multiple Regressions, Kriging, Aurelhy, IDW, etc.) while considering the constraints of our wanted operational system :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hourly updates,&lt;/li&gt;
&lt;li&gt;interpolation at a spatial resolution of 1 km2,&lt;/li&gt;
&lt;li&gt;method valid for historical data,&lt;/li&gt;
&lt;li&gt;flexibility of the code for future implementations,&lt;/li&gt;
&lt;li&gt;method that can be automated,&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The independent variables to be tested for the ‚Äúspatialization‚Äù procedure will notably be :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;slope&lt;/li&gt;
&lt;li&gt;aspect&lt;/li&gt;
&lt;li&gt;altitude&lt;/li&gt;
&lt;li&gt;latitude&lt;/li&gt;
&lt;li&gt;elevation&lt;/li&gt;
&lt;li&gt;distance to the sea&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To insure that the platform will take in account the needs of end-users, a preliminary survey stage will be conducted. This functional analysis would address the following points :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;required weather parameters&lt;/li&gt;
&lt;li&gt;output data formats&lt;/li&gt;
&lt;li&gt;accepted error on the data&lt;/li&gt;
&lt;li&gt;kind of expected output products (risk maps, charts, indicators, etc.)&lt;/li&gt;
&lt;li&gt;expected user-interface&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;validation-phase&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Validation phase&lt;/h2&gt;
&lt;p&gt;Once we have one or more validated methods for each of the meteorological variables to be ‚Äúspatialized‚Äù, will be implemented two custom ‚Äúpilot‚Äù crop monitoring models (orange wheat blossom midge and wheat leaf rust) operated with the ‚Äúspatialized‚Äù weather data from the 16 000 virtual stations. The output results will then be validated by field trials. These tests will allow us to perform the necessary fine-tuning on the algorithms and platform general design prior to its public release.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Configurer un acc√®s SSH √† un h√©bergement mutualis√©</title>
      <link>/post/configurer-un-acces-ssh-a-un-hebergement-mutualise/</link>
      <pubDate>Sun, 30 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/configurer-un-acces-ssh-a-un-hebergement-mutualise/</guid>
      <description>&lt;p&gt;Disposer d‚Äôun d‚Äôacc√®s &lt;a href=&#34;https://code.tutsplus.com/tutorials/ssh-what-and-how--net-25138&#34;&gt;SSH&lt;/a&gt; vous permet de r√©ellement avoir la main sur votre h√©bergement mutualis√© (qui n‚Äôest rien d‚Äôautre qu‚Äôun acc√®s limit√© √† certains dossiers et programmes stock√©s sur un serveur tournant g√©n√©ralement sous Linux).&lt;/p&gt;
&lt;p&gt;Gr√¢ce √† votre acc√®s SSH, vous pourrez notamment y ex√©cuter des commandes &lt;a href=&#34;https://www.tutorialspoint.com/unix/&#34;&gt;unix&lt;/a&gt; et &lt;a href=&#34;https://confluence.atlassian.com/bitbucketserver/basic-git-commands-776639767.html&#34;&gt;git&lt;/a&gt; directement depuis le terminal de votre ordinateur personnel. C‚Äôest l‚Äôoutil id√©al pour la maintenance de votre site WordPress par exemple !&lt;/p&gt;
&lt;p&gt;Avant de vous lancer dans la configuration de votre acc√®s SSH, v√©rifiez d‚Äôabord que votre h√©bergeur offre cette possibilit√©. Ce tutoriel a √©t√© √©labor√© via un h√©bergement &lt;a href=&#34;https://www.infomaniak.com/&#34;&gt;Infomaniak&lt;/a&gt; mais rien ne devrait √™tre fort diff√©rent si vous √™tes chez un autre h√©bergeur offrant cette possibilit√©.&lt;/p&gt;
&lt;p&gt;Ce tutoriel est uniquement valable pour les utilisateurs Linux et Mac. Pour ce qui est de Windows, r√©f√©rez-vous √† un autre tutoriel (faites une recherche sur ‚Äúputty‚Äù).&lt;/p&gt;
&lt;div id=&#34;etape-1-creez-un-compte-dacces-ftpssh-a-votre-espace-mutualise.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Etape 1 : Cr√©ez un compte d‚Äôacc√®s FTP/SSH √† votre espace mutualis√©.&lt;/h3&gt;
&lt;p&gt;Via l‚Äôinterface d‚Äôadministration de votre h√©bergeur, cr√©ez un compte d‚Äôacc√®s FTP/SSH avec mot de passe. Pour Infomaniak, tout est expliqu√© &lt;a href=&#34;https://www.infomaniak.com/fr/support/faq/1982/creermodifiersupprimer-un-compte-ftp-gerer-les-comptesacces-ftp&#34;&gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;etape-2-creez-une-clef-ssh-sur-votre-ordinateur-personnel.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Etape 2 : Cr√©ez une clef SSH sur votre ordinateur personnel.&lt;/h3&gt;
&lt;p&gt;Sur votre ordinateur, ouvrez le terminal (shell) et lancez la commande de cr√©ation d‚Äôune clef SSH :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;myUserName:~$ ssh-keygen -t dsa&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Le shell vous demandera dans quel r√©pertoire vous souhaitez enregistrer votre clef. Appuyez simplement sur enter.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;Generating public /private dsa key pair. Enter file in which to save the 
key (/home/clients/randomStringOfNumbersAndLetters/.ssh/id_dsa): Enter 
passphrase (empty for no passphrase):&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;L‚Äôinvite de commande vous demandera ensuite de cr√©er un mot de passe. Pensez √† un mot de passe facile √† taper car vous serez souvent invit√©s √† l‚Äôentrer :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;Enter passphrase (empty for no passphrase):&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Le shell vous pr√©cisera alors quelle est l‚Äôempreinte de votre clef et son &lt;em&gt;randomart&lt;/em&gt;. La d√©finition de ces termes barbares sort un peu du contexte de ce tutoriel. Je vous invite √† vous documenter par vous-m√™me si vous souhaitez en apprendre un peu plus sur les diff√©rentes subtilit√©s sous-jacentes.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;Your identification has been saved in 
/home/clients/myClientIDNumber/.ssh/id_dsa.
Your public key has been saved in 
/home/clients/myClientIDNumber/.ssh/id_dsa.pub. The key fingerprint is: 
xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx uid68541@h2web77 The 
key&amp;#39;s randomart image is: +--[ DSA 1024]----+ | | | | | | | | | | | | | 
| | | | | +-----------------+&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R√©cup√©rez la chaine de caract√®re correspondant √† votre clef publique :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;myUserName:~$ cat /Users/myUserName/.ssh/id_rsa.pub&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Copiez la clef publique que vous fournit le shell. Exemple de clef fournie :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;ssh -dss 
AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSUGPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XAt3FaoJoAsncM1Q9x5+3V0Ww68``/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/EnmZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbxNrRFi9wrf+M7Q== myUserName@mycomputer.local&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ouvrez un √©diteur de texte (Vim, Nano, Emacs, Atom, gedit, etc), collez-y la clef et enregistrez le fichier sous le nom &lt;em&gt;authorized_keys&lt;/em&gt; (sans extension).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;etape-3-creez-sur-lhebergement-mutualise-le-repertoire-dans-lequel-enregistrer-les-clefs-ssh-autorisees&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Etape 3 : Cr√©ez, sur l‚Äôh√©bergement mutualis√©, le r√©pertoire dans lequel enregistrer les clefs SSH autoris√©es&lt;/h3&gt;
&lt;p&gt;A la racine de votre r√©pertoire, cr√©ez un dossier .ssh dans lequel vous uploadez en FTP ou via l‚Äôinterface en ligne de gestions de fichiers, le fichier &lt;em&gt;authorized_keys&lt;/em&gt; fraichement cr√©√© sur votre ordinateur personnel.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;etape-4-testez-votre-connexion-ssh&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Etape 4 : Testez votre connexion SSH&lt;/h3&gt;
&lt;p&gt;Ca y est, votre ordinateur est maintenant autoris√© √† acc√©der en SSH √† votre espace partag√©. Afin de vous connecter, entrez la commande suivante :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;myComputerName:~ myUserName$ ssh hostFTPSSHlogin@hostServer&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remplacez &lt;code&gt;_hostFTPSSHlogin_&lt;/code&gt; et &lt;code&gt;_hostServer_&lt;/code&gt; par les infos qui vous sont fournis par votre h√©bergeur. Chez infomaniak, vous trouverez ces informations dans votre panneau d‚Äôadministration √† la rubrique :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Accueil/Domaine &amp;amp; H√©bergement/Gestion De sH√©bergements/mon Nom de Domaine/Comptes FT&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Vous serez ensuite invit√©s √† entrer votre mot de passe de connection FTP/SSH cr√©√© √† l‚Äô√©tape 1 :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;hostFTPSSHlogin@hostServerName&amp;#39;s password:&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Entrez-le, validez en appuyant sur enter et si tout ce passe bien, vous devriez maintenant √™tre connect√© en SSH √† votre h√©bergement mutualis√©. Un moyen rapide de voir si votre connection est bien effective, est que votre invite de commande ne commence plus par&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;myComputerName:~ myUserName$&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;mais plut√¥t par quelque chose ressemblant √† ce ceci :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;userName@hostName: /home/clients/randomStringOfNumbersAndLetters $&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Si c‚Äôest le cas, &lt;strong&gt;f√©licitations&lt;/strong&gt; ! Vous disposez maintenant d‚Äôun acc√®s SSH √† votre espace mutualis√©. Gr√¢ce √† cet acc√®s, vous serez par exemple en mesure de &lt;em&gt;puller&lt;/em&gt; les derniers &lt;em&gt;commits&lt;/em&gt; du d√©veloppement de votre site web h√©berg√©s en priv√© sur Bitbucket. Dans un prochain post, nous verrons d‚Äôailleurs comment configurer un workflow de mise en production et mise √† jour de votre site web √† l‚Äôaide de git et SSH.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;etape-5-changez-les-permissions-du-dossier-.ssh-et-du-fichier-authorized_keys&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Etape 5 : Changez les permissions du dossier .ssh et du fichier &lt;em&gt;authorized_keys&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Pour des raisons de s√©curit√©, r√©glez les &lt;a href=&#34;http://www.thinkplexx.com/learn/article/unix/command/chmod-permissions-flags-explained-600-0600-700-777-100-etc&#34;&gt;permissions&lt;/a&gt; de votre dossier .ssh √† 700 et celles du fichier _authorized_keys _√† 600. Ces recommandations proviennent d‚Äô&lt;a href=&#34;https://www.infomaniak.com/en/support/faq/2054/logging-into-your-hosting-with-an-ssh-key&#34;&gt;Infomaniak&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Commencez par vous rendre √† la racine de votre h√©bergement mutualis√©&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;userName@hostName: /home/clients/randomStringOfNumbersAndLetters $ 
cd ~/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R√©glez la permission de votre r√©pertoire .ssh √† 700&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;userName@hostName:~/$ chmod 700 .ssh&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Allez dans le r√©pertoire .ssh contenant le fichier &lt;strong&gt;authorized_keys&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;userName@hostName:~/$ cd .ssh&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R√©glez la permission de votre fichier authorized_keys √† 600&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;userName@hostName:~/.ssh $ chmod 600 authorized_keys&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;etape-6-en-option-changez-le-mot-de-passe-de-votre-clef-ssh&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Etape 6 (en option) : Changez le mot de passe de votre clef SSH&lt;/h3&gt;
&lt;p&gt;Si √† l‚Äôusage, vous vous rendez compte que votre mot de passe est trop fastidieux √† entrer, vous pouvez le changer voire le supprimer (non recommand√©). Pour ce, lorsque vous √™tes connect√©s en SSH √† votre espace mutualis√© (voir √©tape 4) , entrez la commande suivante :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;userName@hostName:/home/clients/randomStringOfNumbersAndLetters $ 
ssh -keygen -p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vous serez alors invit√©s √† entrer le chemin de destination de votre clef :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;Enter file in which the key is 
(/home/clients/randomStringOfNumbersAndLetters/.ssh/id_rsa):&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Entrez le chemin suivant :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;/home/clients/randomStringOfNumbersAndLetters/.ssh/id_dsa&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vous serez invit√©s √† taper l‚Äôancien mot de passe :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;Enter old passphrase:
Key has comment` 
&amp;#39;/home/clients/randomStringOfNumbersAndLetters/.ssh/id_dsa&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Entrez-le et validez en tapant enter.&lt;/p&gt;
&lt;p&gt;L‚Äôinvite de commande vous demandera alors d‚Äôentrer un nouveau mot de passe :&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;Enter new passphrase (empty for no passphrase):&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Choisissez votre nouveau mot de passe ou taper simplement enter pour d√©sactiver l‚Äôutilisation d‚Äôun mot de passe (non recommand√©).&lt;/p&gt;
&lt;p&gt;Si le fait de devoir entrez un mot de passe trop souvent vous ennuie, vous pouvez &lt;a href=&#34;https://unix.stackexchange.com/questions/12195/how-to-avoid-being-asked-passphrase-each-time-i-push-to-bitbucket&#34;&gt;cr√©er un &lt;strong&gt;agent&lt;/strong&gt;&lt;/a&gt; qui le retiendra pour vous lors de la session active.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Meta</title>
      <link>/about/colofon/</link>
      <pubDate>Sat, 01 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/about/colofon/</guid>
      <description>&lt;div id=&#34;why-this-website&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Why this website ?&lt;/h1&gt;
&lt;p&gt;A website is highly useful for yourself to keep track of what you have done and thought. Sometimes you may go back to a certain old post of yours to relearn the tricks or methods you once mastered in the past but have forgotten.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-is-it-built&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How is it built ?&lt;/h1&gt;
&lt;p&gt;This website is built with &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;R blogdown&lt;/a&gt; which uses a combination of Hugo, Rmarkdown and knitr.&lt;/p&gt;
&lt;p&gt;Its source code is publicly availbale on &lt;a href=&#34;https://github.com/pokyah-hugo-blog-source&#34;&gt;github&lt;/a&gt;. Don‚Äôt hesitate to fork, appropriate, edit and improve.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;licenses&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Licenses&lt;/h1&gt;
&lt;p&gt;The Stackoverlow and Spotify icons are provided by &lt;a href=&#34;Creative%20Commons%20Attribution%204.0&#34;&gt;fontawesome under the Creative Commons Attribution 4.0 License&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Copyright : Thomas Goossens - &lt;a href=&#34;mailto:hello.pokyah@gmail.com&#34;&gt;hello.pokyah@gmail.com&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>